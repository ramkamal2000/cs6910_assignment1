{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Try_dl_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9-final"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "761045a0087246b18ab5ad30dfa2b21a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ad9ee386314b4efe95d5e403d05dd6de",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a9c511f171d148ae8a60060db79d0d31",
              "IPY_MODEL_dc19a6b0f3444ebea5143c44b3cd3638"
            ]
          }
        },
        "ad9ee386314b4efe95d5e403d05dd6de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a9c511f171d148ae8a60060db79d0d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a0190965b67240a5885a51cf9dc44163",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3375,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3375,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c54efae36c54ee3879926645832798d"
          }
        },
        "dc19a6b0f3444ebea5143c44b3cd3638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d96301313c544fefab941ff6d2d75b42",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3375/3375 [00:39&lt;00:00, 84.93it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9f554f4d1d364daa985a791f65f1dbed"
          }
        },
        "a0190965b67240a5885a51cf9dc44163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c54efae36c54ee3879926645832798d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d96301313c544fefab941ff6d2d75b42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9f554f4d1d364daa985a791f65f1dbed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "475a8bd6a54a4504a8218fce59289cb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_97151dc6dcfd4dfbbba8472cb8c9585a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3be76f1894c04049adf068aab3d27e43",
              "IPY_MODEL_a7b9e78189e74af982d58f4c5d244f03"
            ]
          }
        },
        "97151dc6dcfd4dfbbba8472cb8c9585a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3be76f1894c04049adf068aab3d27e43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ad3fa7a799614bcda5cd715b7dfd3fa1",
            "_dom_classes": [],
            "description": " 35%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 3375,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1190,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f3dbd3696fb5405e940a608cf1cbe7c7"
          }
        },
        "a7b9e78189e74af982d58f4c5d244f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_855bbc0feab543b7b2a9110d6678eb89",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1190/3375 [00:20&lt;00:38, 56.73it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e3639f7f1434defba9de6044264852d"
          }
        },
        "ad3fa7a799614bcda5cd715b7dfd3fa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f3dbd3696fb5405e940a608cf1cbe7c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "855bbc0feab543b7b2a9110d6678eb89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e3639f7f1434defba9de6044264852d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_k91V7UYQl6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "687bfbdc-847f-494e-b912-88ed61b1991b"
      },
      "source": [
        "!pip install wandb\n",
        "!pip install tensorflow\n",
        "!pip install keras\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from tqdm.auto import tqdm\n",
        "import tensorflow as tf\n",
        "import wandb\n",
        "import pprint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.10.22)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.0.2)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.14)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (54.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.1)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (54.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.27.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeEC-1yko45f"
      },
      "source": [
        "# wandb.login(key='14394907543f59ea21931529e34b4d80d2ca8c9c')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjPTg70-YXjM"
      },
      "source": [
        "# Question 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESi2E1-zC6GV"
      },
      "source": [
        "def load_mnist(return_images=False):\n",
        "\n",
        "  (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "  train_shuffler = np.random.shuffle(np.arange(60000))\n",
        "  x_train, y_train = x_train[train_shuffler][0], y_train[train_shuffler][0]\n",
        "\n",
        "  test_shuffler = np.random.shuffle(np.arange(10000))\n",
        "  x_test, y_test = x_test[test_shuffler][0], y_test[test_shuffler][0]\n",
        "\n",
        "  x_train = np.array(x_train/255).astype('float32')\n",
        "  x_test = np.array(x_test/255).astype('float32')\n",
        "\n",
        "  x_train, x_val = x_train[:54000], x_train[54000:]\n",
        "  y_train, y_val = y_train[:54000], y_train[54000:]\n",
        "\n",
        "\n",
        "  if (return_images==False):\n",
        "    return {\n",
        "        'train': {\n",
        "            'X': x_train.reshape([-1, 784]),\n",
        "            'Y': y_train.reshape([54000])\n",
        "        },\n",
        "        'val': {\n",
        "            'X': x_val.reshape([-1, 784]),\n",
        "            'Y': y_val.reshape([6000])\n",
        "        },\n",
        "        'test': {\n",
        "            'X': x_test.reshape([-1, 784]),\n",
        "            'Y': y_test.reshape([10000])\n",
        "        }\n",
        "  }\n",
        "\n",
        "  else :\n",
        "    return {\n",
        "      'train': {\n",
        "          \t'X': x_train,\n",
        "          \t'Y': y_train\n",
        "      },\n",
        "      'val': {\n",
        "            'X': x_val,\n",
        "            'Y': y_val\n",
        "      },\n",
        "      'test': {\n",
        "            'X': x_test,\n",
        "            'Y': y_test\n",
        "      }\n",
        "    }\n",
        "\n",
        "\n",
        "data = load_mnist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr-EXaU4oiZ_"
      },
      "source": [
        "# Question 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23nXB0VBojt0"
      },
      "source": [
        "class neural_network:\n",
        "\n",
        "  # constructor function - initializes weights\n",
        "  def __init__(self, dict_layers, initializer):\n",
        "\n",
        "    self.weights_list = []\n",
        "    self.biases_list = []\n",
        "    self.dict_layers= dict_layers\n",
        "\n",
        "    self.weights_list, self.biases_list = wandb_initializer(dict_layers, self.weights_list, self.biases_list, initializer)\n",
        "\n",
        "  # function to compute forward propogation\n",
        "  def forward_prop(self, W, b, X, Y, activation_func):\n",
        "\n",
        "    A = []\n",
        "    H = []\n",
        "    \n",
        "    H_pre = X\n",
        "    \n",
        "    L = self.dict_layers['num_hidden_layers']\n",
        "\n",
        "    for i in range(L) :\n",
        "      A.append(W[i] @ H_pre + b[i])\n",
        "      H_pre = getattr(activation, activation_func)(A[i])\n",
        "      H.append(H_pre)\n",
        "    \n",
        "    A.append(W[L] @ H_pre + b[L])\n",
        "    \n",
        "    Y_hat = activation.softmax(A[L])\n",
        "    \n",
        "    return {\n",
        "        'A' : A,\n",
        "        'H' : H,\n",
        "        'Y_hat' : Y_hat\n",
        "    }\n",
        "\n",
        "  # helper function to perform forward propogation \n",
        "  def self_forward_prop(self, X, Y, activation_func) :\n",
        "\n",
        "    temp = self.forward_prop(self.weights_list,self.biases_list, X, Y, activation_func)\n",
        "    return temp\n",
        "\n",
        "  # function to perform backward propogration\n",
        "  def back_prop(self, W, b, A, H, Y_hat, X, Y,activation_func):\n",
        "\n",
        "    batch_size = len(Y)\n",
        "    \n",
        "    del_w = []\n",
        "    del_b = []\n",
        "    L = self.dict_layers['num_hidden_layers']\n",
        "    \n",
        "    E = np.zeros(Y_hat.shape)\n",
        "    E[Y,np.arange(batch_size)] = 1\n",
        "    \n",
        "    grad_A = -(E - Y_hat)\n",
        "\n",
        "    for i in range(L,-1,-1) :\n",
        "\n",
        "      temp1 = grad_A.reshape(-1,batch_size)\n",
        "      \n",
        "      if i==0 :\n",
        "        temp2 = X.T\n",
        "      else :\n",
        "        temp2 = H[i-1].reshape((batch_size ,-1))\n",
        "\n",
        "      del_w.append(temp1 @ temp2/batch_size)\n",
        "      del_b.append(grad_A/batch_size)\n",
        "\n",
        "      if(i!=0) :\n",
        "        grad_H = W[i].T @ grad_A      \n",
        "        grad_A = grad_H * getattr(activation,activation_func+'_der')(H[i-1])\n",
        "\n",
        "    for j in range(len(del_b)) :\n",
        "       del_b[j] = np.sum(del_b[j],axis=1)\n",
        "\n",
        "    return {\n",
        "        'dw' : del_w,\n",
        "        'db' : del_b\n",
        "    }\n",
        "\n",
        "  # helper function to perform backward propogation\n",
        "  def self_back_prop(self, A, H, Y_hat, X, Y,activation_func) :\n",
        "    temp = self.back_prop(self.weights_list,self.biases_list, A, H, Y_hat, X, Y, activation_func)\n",
        "    return temp\n",
        "\n",
        "  #  function to compute gradient\n",
        "  def grad_wandb(self, W, b, X, Y,activation_func):\n",
        "\n",
        "    X = X.T.reshape((784,-1))\n",
        "    \n",
        "    temp = self.forward_prop(W, b, X, Y, activation_func)\n",
        "    temp2 = self.back_prop(W, b, temp['A'], temp['H'], temp['Y_hat'], X, Y, activation_func)\n",
        "\n",
        "    return {\n",
        "        'dw' : temp2['dw'],\n",
        "        'db' : temp2['db']\n",
        "    }\n",
        "\n",
        "  # helper function to compute gradient\n",
        "  def self_grad_wandb(self, X, Y, activation_func) :\n",
        "    temp = self.grad_wandb(self.weights_list, self.biases_list, X, Y,activation_func)\n",
        "    return temp\n",
        "\n",
        "  # function to compute predictions\n",
        "  def predict(self, X, activation_func):\n",
        "    X = X.T.reshape((784,-1))\n",
        "    temp = self.forward_prop(self.weights_list,self.biases_list, X, 0, activation_func)\n",
        "    return {\n",
        "      'Y' : np.argmax(temp['Y_hat'],axis=0),\n",
        "      'Y_hat' : temp['Y_hat']\n",
        "    }\n",
        "\n",
        "  # function to update weights and biases\n",
        "  def update_vals(self, dw, db, wd) :\n",
        "    L = len(self.weights_list)\n",
        "    for i in range(L) :\n",
        "      self.weights_list[i] =self.weights_list[i] - dw[L-i-1].reshape(self.weights_list[i].shape) - wd * self.weights_list[i]\n",
        "\n",
        "    #for i in range(len(self.biases_list)) :\n",
        "      self.biases_list[i] =self.biases_list[i] - db[L-i-1].reshape(self.biases_list[i].shape)  \n",
        "##################################################################################\n",
        "class activation:\n",
        "  \n",
        "  @staticmethod\n",
        "  def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "  \n",
        "  @staticmethod\n",
        "  def relu(z):\n",
        "    return (z>0) * z\n",
        "\n",
        "  @staticmethod\n",
        "  def tanh(z):\n",
        "    return np.tanh(z)\n",
        "\n",
        "  @staticmethod\n",
        "  def sigmoid_der(z) :\n",
        "    return z * (1-z)\n",
        "  \n",
        "  @staticmethod\n",
        "  def relu_der(z) :\n",
        "    return (z>0)\n",
        "\n",
        "  @staticmethod\n",
        "  def tanh_der(z):\n",
        "    return 1 - z*z\n",
        "\n",
        "  @staticmethod\n",
        "  def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / np.sum(e_x,axis=0)\n",
        "\n",
        "##################################################################################\n",
        "def set_nn_shape(verbose=True, num_hidden_layers=-1, hidden_layer_size=-1):\n",
        "\n",
        "  input_layer_size = 784\n",
        "  hidden_layer_size = hidden_layer_size\n",
        "  num_hidden_layers = num_hidden_layers\n",
        "  output_layer_size = 10\n",
        "  \n",
        "  # input_layer_size = 3\n",
        "  # hidden_layer_size = hidden_layer_size\n",
        "  # num_hidden_layers = num_hidden_layers\n",
        "  # output_layer_size = 2\n",
        "  if (verbose):\n",
        "    print(\"\\nNumber Of Hidden Layers:\")\n",
        "    num_hidden_layers = int(input())\n",
        "\n",
        "    print(\"\\nSize Of Each Hidden Layer:\")\n",
        "    hidden_layer_size = int(input())\n",
        "\n",
        "    print(f\"\\nThe Neural Network Has {num_hidden_layers+2} Layers In Total!\")\n",
        "  \n",
        "  return {\"input_layer_size\": input_layer_size, \"hidden_layer_size\": hidden_layer_size, \"output_layer_size\": output_layer_size, \"num_hidden_layers\": num_hidden_layers}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIFMpZQNItG3"
      },
      "source": [
        "def wandb_initializer(nn_shape, weights_list, biases_list, type='random', mu = 0, sigma = 1):\n",
        "  \n",
        "  # random initialization\n",
        "  if (type=='random'):\n",
        "    initializer = tf.keras.initializers.TruncatedNormal(mean=mu, stddev=sigma)\n",
        "  \n",
        "  # xavier initialization\n",
        "  elif (type=='xavier'):\n",
        "    initializer = tf.keras.initializers.GlorotNormal()\n",
        "\n",
        "  weights_list.append(initializer(shape=(nn_shape['hidden_layer_size'], nn_shape['input_layer_size'])).numpy())\n",
        "  biases_list.append(initializer(shape=(nn_shape['hidden_layer_size'], 1)).numpy())\n",
        "  for i in range(nn_shape['num_hidden_layers'] - 1):\n",
        "    weights_list.append(initializer(shape=(nn_shape['hidden_layer_size'], nn_shape['hidden_layer_size'])).numpy())\n",
        "    biases_list.append(initializer(shape=(nn_shape['hidden_layer_size'], 1)).numpy())\n",
        "\n",
        "  weights_list.append(initializer(shape=(nn_shape['output_layer_size'], nn_shape['hidden_layer_size'])).numpy())\n",
        "  biases_list.append(initializer(shape=(nn_shape['output_layer_size'], 1)).numpy())\n",
        "\n",
        "  return weights_list, biases_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVpF16BtXqB_"
      },
      "source": [
        "class optimizer:\n",
        "\n",
        "  @staticmethod\n",
        "  def sgd(network, data, config):\n",
        "\n",
        "    num_epochs, batch_size = config['num_epochs'], config['batch_size']\n",
        "    eta, lambda_ = config['lr'], config['weight_decay']\n",
        "    initializer, activation_func = config['weights_initializer'], config['activation']\n",
        " \n",
        "    X_train, Y_train = data['train']['X'], data['train']['Y']\n",
        "    num_examples = len(X_train)\n",
        "\n",
        "    for i in range(num_epochs):\n",
        "      for k in tqdm(range(0, len(X_train), batch_size)) :\n",
        "        X = X_train[k: k+batch_size]\n",
        "        Y = Y_train[k: k+batch_size]\n",
        "        temp = network.self_grad_wandb(X, Y, activation_func)         \n",
        "        dw = temp['dw']\n",
        "        db = temp['db']\n",
        "        for dd in dw :\n",
        "          dd*= eta\n",
        "        for dd in db :\n",
        "          dd*=eta\n",
        "\n",
        "        network.update_vals(dw, db, lambda_)\n",
        "    \n",
        "      report = run_callback(network, data, config) \n",
        "        \n",
        "      wandb.log({\n",
        "            'batch_size': config.batch_size, \n",
        "            'val_loss' : report['loss']['val'], \n",
        "            'train_loss': report['loss']['train'],\n",
        "            'train_acc': report['accuracy']['train'],\n",
        "            'val_acc': report['accuracy']['val']  \n",
        "      }) \n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def momentum(network, data, config,gamma = 0.9) :\n",
        "    num_epochs, batch_size = config['num_epochs'], config['batch_size']\n",
        "    eta, lambda_ = config['lr'], config['weight_decay']\n",
        "    initializer, activation_func = config['weights_initializer'], config['activation']\n",
        "    \n",
        "    X_train, Y_train = data['train']['X'], data['train']['Y']\n",
        "    num_examples = len(X_train)\n",
        "\n",
        "    nn_shape = set_nn_shape(False, config['num_hidden_layers'], config['hidden_layer_size'])\n",
        "    dw, db = wandb_initializer(nn_shape, [], [], 'random', 0, 0)\n",
        "\n",
        "    dw.reverse()\n",
        "    db.reverse()\n",
        "\n",
        "    for j in range(len(db)) :\n",
        "      db[j] = db[j].flatten()\n",
        "\n",
        "    for i in range(num_epochs) :\n",
        "      for k in tqdm(range(0, len(X_train), batch_size)) :\n",
        "        X = X_train[k:k+batch_size]\n",
        "        Y = Y_train[k:k+batch_size]\n",
        "        temp = network.self_grad_wandb(X,Y,activation_func)       \n",
        "        for j in range(len(dw)) :\n",
        "          dw[j] += eta*temp['dw'][j]\n",
        "          db[j] += eta*temp['db'][j]\n",
        "\n",
        "        network.update_vals(dw,db, lambda_)\n",
        "        for dd in db :\n",
        "          dd*=gamma\n",
        "        for dd in dw :\n",
        "          dd*=gamma\n",
        "\n",
        "      report = run_callback(network, data, config) \n",
        "        \n",
        "      wandb.log({\n",
        "            'batch_size': config.batch_size, \n",
        "            'val_loss' : report['loss']['val'], \n",
        "            'train_loss': report['loss']['train'],\n",
        "            'train_acc': report['accuracy']['train'],\n",
        "            'val_acc': report['accuracy']['val']  \n",
        "      }) \n",
        "        \n",
        "  @staticmethod\n",
        "  def NAG(network, data, config,gamma = 0.9) :\n",
        "    num_epochs, batch_size = config['num_epochs'], config['batch_size']\n",
        "    eta, lambda_ = config['lr'], config['weight_decay']\n",
        "    initializer, activation_func = config['weights_initializer'], config['activation']\n",
        "    \n",
        "    X_train, Y_train = data['train']['X'], data['train']['Y']\n",
        "    \n",
        "    nn_shape = set_nn_shape(False, config['num_hidden_layers'], config['hidden_layer_size'])\n",
        "    v_dw, v_db = wandb_initializer(nn_shape, [], [], 'random', 0, 0)\n",
        "\n",
        "    v_dw.reverse()\n",
        "    v_db.reverse()\n",
        "\n",
        "    for j in range(len(v_db)) :\n",
        "      v_db[j] = v_db[j].flatten()\n",
        "\n",
        "    for i in range(num_epochs) :\n",
        "      for k in tqdm(range(0, len(X_train), batch_size)) :\n",
        "        for j in range(len(v_dw)) :\n",
        "          v_dw[j] = gamma*v_dw[j]\n",
        "          v_db[j] = gamma*v_db[j]\n",
        "\n",
        "        X = X_train[k:k+batch_size]\n",
        "        Y = Y_train[k:k+batch_size]\n",
        "        \n",
        "        W = network.weights_list.copy()\n",
        "        B = network.biases_list.copy()\n",
        "\n",
        "        L = len(W)\n",
        "        for j in range(L) :\n",
        "          W[j] -= v_dw[L-j-1]\n",
        "          B[j] -= v_db[L-j-1].reshape(B[j].shape)\n",
        "\n",
        "        temp = network.grad_wandb(W,B,X,Y,activation_func)  \n",
        "\n",
        "        for j in range(len(v_dw)) :\n",
        "          v_dw[j] += eta*temp['dw'][j]\n",
        "          v_db[j] += eta*temp['db'][j]\n",
        "\n",
        "\n",
        "        network.update_vals(v_dw,v_db,lambda_)\n",
        "\n",
        "      report = run_callback(network, data, config) \n",
        "        \n",
        "      wandb.log({\n",
        "            'batch_size': config.batch_size, \n",
        "            'val_loss' : report['loss']['val'], \n",
        "            'train_loss': report['loss']['train'],\n",
        "            'train_acc': report['accuracy']['train'],\n",
        "            'val_acc': report['accuracy']['val']  \n",
        "      }) \n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def RMSprop(network, data, config,beta = 0.9,epsilon = 1e-8) :\n",
        "    \n",
        "    num_epochs, batch_size = config['num_epochs'], config['batch_size']\n",
        "    eta, lambda_ = config['lr'], config['weight_decay']\n",
        "    initializer, activation_func = config['weights_initializer'], config['activation']\n",
        "    \n",
        "    X_train, Y_train = data['train']['X'], data['train']['Y']\n",
        "    num_examples = len(X_train)\n",
        "\n",
        "    nn_shape = set_nn_shape(False, config['num_hidden_layers'], config['hidden_layer_size'])\n",
        "    v_dw, v_db = wandb_initializer(nn_shape, [], [], 'random', 0, 0)\n",
        "\n",
        "    v_dw.reverse()\n",
        "    v_db.reverse()\n",
        "\n",
        "    for j in range(len(v_db)) :\n",
        "      v_db[j] = v_db[j].flatten()\n",
        "\n",
        "    for i in range(num_epochs) :\n",
        "      dw = []\n",
        "      db = []\n",
        "      for k in tqdm(range(0, len(X_train), batch_size)) :\n",
        "        X = X_train[k:k+batch_size]\n",
        "        Y = Y_train[k:k+batch_size]\n",
        "        temp = network.self_grad_wandb(X,Y,activation_func)  \n",
        "\n",
        "        dw = temp['dw']\n",
        "        db = temp['db']\n",
        "\n",
        "        for j in range(len(dw)) :\n",
        "          v_dw[j] *= beta\n",
        "          v_dw[j] += (1-beta)*(dw[j]**2) \n",
        "          dw[j] *= eta/np.sqrt(v_dw[j]+epsilon)\n",
        "          v_db[j] *= beta\n",
        "          v_db[j] += (1-beta)*(db[j]**2) \n",
        "          db[j] *= eta/np.sqrt(v_db[j]+epsilon)\n",
        "\n",
        "        network.update_vals(dw,db, lambda_)\n",
        "\n",
        "      report = run_callback(network, data, config) \n",
        "        \n",
        "      wandb.log({\n",
        "            'batch_size': config.batch_size, \n",
        "            'val_loss' : report['loss']['val'], \n",
        "            'train_loss': report['loss']['train'],\n",
        "            'train_acc': report['accuracy']['train'],\n",
        "            'val_acc': report['accuracy']['val']  \n",
        "      }) \n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def adam(network, data, config, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
        "\n",
        "    num_epochs, batch_size = config['num_epochs'], config['batch_size']\n",
        "    eta, lambda_ = config['lr'], config['weight_decay']\n",
        "    initializer, activation_func = config['weights_initializer'], config['activation']\n",
        " \n",
        "   \n",
        "    X_train, Y_train = data['train']['X'], data['train']['Y']\n",
        "    num_examples = len(X_train)\n",
        "    nn_shape = set_nn_shape(False, config['num_hidden_layers'], config['hidden_layer_size'])\n",
        "\n",
        "    m_w, m_b = wandb_initializer(nn_shape, [], [], 'random', 0, 0)\n",
        "    v_w, v_b = wandb_initializer(nn_shape, [], [], 'random', 0, 0)\n",
        "\n",
        "    m_w.reverse()\n",
        "    m_b.reverse()\n",
        "    v_w.reverse()\n",
        "    v_b.reverse()\n",
        "    for j in range(len(m_b)):\n",
        "      m_b[j], v_b[j] = m_b[j].flatten(), v_b[j].flatten() \n",
        "    \n",
        "    t = 0\n",
        "    for i in range(num_epochs):\n",
        "      for k in tqdm(range(0, len(X_train), batch_size)) :\n",
        "        \n",
        "        t += 1\n",
        "        \n",
        "        X = X_train[k: k+batch_size]\n",
        "        Y = Y_train[k: k+batch_size]\n",
        "        \n",
        "        temp = network.self_grad_wandb(X, Y, activation_func)\n",
        "        \n",
        "        dw = temp['dw']\n",
        "        db = temp['db']\n",
        "        \n",
        "        for j in range(len(dw)):\n",
        "          \n",
        "          m_w[j] = beta1 * m_w[j] + (1 - beta1) * dw[j]\n",
        "          m_b[j] = beta1 * m_b[j] + (1 - beta1) * db[j]\n",
        "          \n",
        "          v_w[j] = beta2 * v_w[j] + (1 - beta2) * dw[j] * dw[j]\n",
        "          v_b[j] = beta2 * v_b[j] + (1 - beta2) * db[j] * db[j]\n",
        "                 \n",
        "          m_w[j] = m_w[j] *((1-beta1**int(t))/ (1-beta1**int(t+1)))\n",
        "          m_b[j] = m_b[j] *((1-beta1**int(t))/ (1-beta1**int(t+1)))\n",
        "          \n",
        "          v_w[j] = v_w[j]*((1-beta2**int(t))/ (1-beta2**int(t+1)))\n",
        "          v_b[j] = v_b[j]*((1-beta2**int(t))/ (1-beta2**int(t+1)))\n",
        "          \n",
        "          dw[j] = eta * m_w[j] / (epsilon + np.sqrt( v_w[j]))\n",
        "          db[j] = eta * m_b[j] / ( epsilon + np.sqrt(v_b[j]))\n",
        "\n",
        "         \n",
        "        network.update_vals(dw, db, lambda_)\n",
        "        \n",
        "      report = run_callback(network, data, config) \n",
        "        \n",
        "      wandb.log({\n",
        "            'batch_size': config.batch_size, \n",
        "            'val_loss' : report['loss']['val'], \n",
        "            'train_loss': report['loss']['train'],\n",
        "            'train_acc': report['accuracy']['train'],\n",
        "            'val_acc': report['accuracy']['val']  \n",
        "      })\n",
        "\n",
        "    \n",
        "  @staticmethod\n",
        "  def nadam(network, data, config, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
        "\n",
        "    num_epochs, batch_size = config['num_epochs'], config['batch_size']\n",
        "    eta, lambda_ = config['lr'], config['weight_decay']\n",
        "    initializer, activation_func = config['weights_initializer'], config['activation']\n",
        " \n",
        "    X_train, Y_train = data['train']['X'], data['train']['Y']\n",
        "    num_examples = len(X_train)\n",
        "    \n",
        "    nn_shape = set_nn_shape(False, config['num_hidden_layers'], config['hidden_layer_size'])\n",
        "\n",
        "    m_w, m_b = wandb_initializer(nn_shape, [], [], 'random', 0, 0)\n",
        "    v_w, v_b = wandb_initializer(nn_shape, [], [], 'random', 0, 0)\n",
        "\n",
        "    m_w.reverse()\n",
        "    m_b.reverse()\n",
        "    v_w.reverse()\n",
        "    v_b.reverse()\n",
        "    for j in range(len(m_b)):\n",
        "      m_b[j], v_b[j] = m_b[j].flatten(), v_b[j].flatten() \n",
        "    \n",
        "    t = 0\n",
        "    for i in range(num_epochs):\n",
        "      for k in tqdm(range(0, len(X_train), batch_size)) :\n",
        "        \n",
        "        t += 1\n",
        "        \n",
        "        X = X_train[k: k+batch_size]\n",
        "        Y = Y_train[k: k+batch_size]\n",
        "        \n",
        "        temp = network.self_grad_wandb(X, Y, activation_func)\n",
        "        \n",
        "        dw = temp['dw']\n",
        "        db = temp['db']\n",
        "        \n",
        "        for j in range(len(dw)):\n",
        "          \n",
        "          m_w[j] = beta1 * m_w[j] + (1 - beta1) * dw[j]\n",
        "          m_b[j] = beta1 * m_b[j] + (1 - beta1) * db[j]\n",
        "          \n",
        "          v_w[j] = beta2 * v_w[j] + (1 - beta2) * dw[j] * dw[j]\n",
        "          v_b[j] = beta2 * v_b[j] + (1 - beta2) * db[j] * db[j]\n",
        "                 \n",
        "          m_w[j] = m_w[j] *((1-beta1**int(t))/ (1-beta1**int(t+1)))\n",
        "          m_b[j] = m_b[j] *((1-beta1**int(t))/ (1-beta1**int(t+1)))\n",
        "          \n",
        "          v_w[j] = v_w[j]*((1-beta2**int(t))/ (1-beta2**int(t+1)))\n",
        "          v_b[j] = v_b[j]*((1-beta2**int(t))/ (1-beta2**int(t+1)))\n",
        "          \n",
        "          \n",
        "          dw[j] = eta * (beta1*m_w[j] + (1 - beta1)*dw[j]) / (epsilon + np.sqrt( v_w[j]))\n",
        "          db[j] = eta * (beta1*m_b[j] + (1 - beta1)*db[j]) / ( epsilon + np.sqrt(v_b[j]))\n",
        "        \n",
        "        network.update_vals(dw, db, lambda_)\n",
        "        \n",
        "      report = run_callback(network, data, config) \n",
        "        \n",
        "      wandb.log({\n",
        "            'batch_size': config.batch_size, \n",
        "            'val_loss' : report['loss']['val'], \n",
        "            'train_loss': report['loss']['train'],\n",
        "            'train_acc': report['accuracy']['train'],\n",
        "            'val_acc': report['accuracy']['val']  \n",
        "      })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKDlM0FUKutJ"
      },
      "source": [
        "def run_callback(network,data,config) :\n",
        "    \n",
        "    activation_func = config['activation']\n",
        "    \n",
        "    X_train = data['train']['X']\n",
        "    Y_train = data['train']['Y']\n",
        "\n",
        "    X_val = data['val']['X']\n",
        "    Y_val = data['val']['Y']\n",
        "\n",
        "    train_loss = 0\n",
        "    train_count = 0\n",
        "    train_sq_error = 0\n",
        "    \n",
        "    temp = network.predict(X_train,activation_func)\n",
        "    train_count = np.sum(temp['Y'].reshape(Y_train.shape)==Y_train)\n",
        "    \n",
        "    Y_pred = np.array(temp['Y_hat'].T)\n",
        "    train_loss = np.sum(-np.log(Y_pred[np.arange(len(X_train)),Y_train]))\n",
        "    E = np.zeros(Y_pred.shape)\n",
        "    E[np.arange(len(X_train)),Y_train] = 1\n",
        "    train_sq_error = np.sum((E-Y_pred)**2)\n",
        "\n",
        "    val_loss = 0\n",
        "    val_count = 0\n",
        "    val_sq_error = 0\n",
        "    \n",
        "    temp = network.predict(X_val, activation_func)\n",
        "    val_count = np.sum(temp['Y'].reshape(Y_val.shape)==Y_val)\n",
        "    \n",
        "    Y_pred = np.array(temp['Y_hat'].T)\n",
        "    val_loss = np.sum(-np.log(Y_pred[np.arange(len(X_val)),Y_val]))\n",
        "    E = np.zeros(Y_pred.shape)\n",
        "    E[np.arange(len(X_val)),Y_val] = 1\n",
        "    val_sq_error = np.sum((E-Y_pred)**2)\n",
        "    \n",
        "    return  {\n",
        "        'loss': {\n",
        "            'train' : train_loss / len(X_train),\n",
        "            'val' : val_loss / len(X_val)\n",
        "        },\n",
        "        'accuracy': {\n",
        "            'train': train_count / len(X_train),\n",
        "            'val': val_count / len(X_val)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9IjksI6O6wE"
      },
      "source": [
        "sweep_config = {\n",
        "    'method' : 'grid',\n",
        "\n",
        "    'parameters': {\n",
        "        'num_epochs': {\n",
        "            'values': [10]\n",
        "        },\n",
        "        'num_hidden_layers': {\n",
        "            'values': [5]\n",
        "        },\n",
        "        'hidden_layer_size': {\n",
        "            'values': [256]\n",
        "        },\n",
        "        'weight_decay': {\n",
        "            'values': [0]\n",
        "        },\n",
        "        'lr': {\n",
        "            'values': [1e-4, 5e-4, 1e-3]\n",
        "        },\n",
        "        'optimizer': {\n",
        "            'values': ['momentum', 'RMSprop', 'adam', 'nadam']\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [32, 16]\n",
        "        },\n",
        "        'weights_initializer': {\n",
        "            'values': ['xavier']\n",
        "        },\n",
        "        'activation': {\n",
        "            'values': ['relu']\n",
        "        }        \n",
        "    }\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F91KWHHABHv5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4777a38-f35a-422a-b102-79cb598c8914"
      },
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project='mnist')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: xmq2ybik\n",
            "Sweep URL: https://wandb.ai/ramkamal/new_fashion/sweeps/xmq2ybik\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fhn-A6mcO6wF",
        "outputId": "6eb0d2aa-3cbe-44b0-f5f7-3625899d3aff"
      },
      "source": [
        "pprint.pprint(sweep_config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'method': 'bayes',\n",
            " 'metric': {'goal': 'maximize', 'name': 'val_acc'},\n",
            " 'parameters': {'activation': {'values': ['sigmoid', 'tanh', 'relu']},\n",
            "                'batch_size': {'values': [64, 32, 16]},\n",
            "                'hidden_layer_size': {'values': [32, 64, 128, 256]},\n",
            "                'lr': {'values': [0.0001, 0.0005, 0.001, 0.005]},\n",
            "                'num_epochs': {'values': [5, 10]},\n",
            "                'num_hidden_layers': {'values': [3, 4, 5]},\n",
            "                'optimizer': {'values': ['sgd',\n",
            "                                         'momentum',\n",
            "                                         'NAG',\n",
            "                                         'RMSprop',\n",
            "                                         'adam',\n",
            "                                         'nadam']},\n",
            "                'weight_decay': {'values': [0.5, 0.05, 0.005, 0.0005, 0]},\n",
            "                'weights_initializer': {'values': ['random', 'xavier']}}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qml5BFsMO6wF"
      },
      "source": [
        "class sweep_module:\n",
        "  @staticmethod\n",
        "  def train(config=None):\n",
        "\n",
        "    with wandb.init(config):\n",
        "      \n",
        "      config = wandb.config\n",
        "      wandb.run.name = 'ac:'+config['activation'][:3]+'_opt:'+config['optimizer'][:4]+'_hl:'+str(config['num_hidden_layers'])+':'+str(config['hidden_layer_size'])\n",
        "      \n",
        "      nn_shape = set_nn_shape(False, config['num_hidden_layers'] , config['hidden_layer_size'])\n",
        "      \n",
        "      network = neural_network(nn_shape, config['weights_initializer'])\n",
        "      \n",
        "      getattr(optimizer, config['optimizer'])(network, data, config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCYYRxwNO6wF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404,
          "referenced_widgets": [
            "761045a0087246b18ab5ad30dfa2b21a",
            "ad9ee386314b4efe95d5e403d05dd6de",
            "a9c511f171d148ae8a60060db79d0d31",
            "dc19a6b0f3444ebea5143c44b3cd3638",
            "a0190965b67240a5885a51cf9dc44163",
            "4c54efae36c54ee3879926645832798d",
            "d96301313c544fefab941ff6d2d75b42",
            "9f554f4d1d364daa985a791f65f1dbed",
            "475a8bd6a54a4504a8218fce59289cb9",
            "97151dc6dcfd4dfbbba8472cb8c9585a",
            "3be76f1894c04049adf068aab3d27e43",
            "a7b9e78189e74af982d58f4c5d244f03",
            "ad3fa7a799614bcda5cd715b7dfd3fa1",
            "f3dbd3696fb5405e940a608cf1cbe7c7",
            "855bbc0feab543b7b2a9110d6678eb89",
            "0e3639f7f1434defba9de6044264852d"
          ]
        },
        "outputId": "bb928782-cb4f-47fb-d793-a3ae36557c67"
      },
      "source": [
        "# performing the sweep\n",
        "wandb.agent(sweep_id, sweep_module.train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f6zv3cnv with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: sigmoid\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_hidden_layers: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: momentum\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweights_initializer: random\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mramkamal\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.22<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">rose-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/ramkamal/new_fashion\" target=\"_blank\">https://wandb.ai/ramkamal/new_fashion</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/ramkamal/new_fashion/sweeps/xmq2ybik\" target=\"_blank\">https://wandb.ai/ramkamal/new_fashion/sweeps/xmq2ybik</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/ramkamal/new_fashion/runs/f6zv3cnv\" target=\"_blank\">https://wandb.ai/ramkamal/new_fashion/runs/f6zv3cnv</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210315_113842-f6zv3cnv</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "761045a0087246b18ab5ad30dfa2b21a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=3375.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "475a8bd6a54a4504a8218fce59289cb9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=3375.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eyf1aCj-pJpv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
