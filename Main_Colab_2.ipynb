{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of DL Assignment 1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9-final"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ed91123207604a5a9f5e57c3eec30bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a0d62d16a41545579130cf91ac521fb4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f0530b7a82234b93878cbcb574e57aac",
              "IPY_MODEL_9966ae96912e4b46ba1e89a576e14316"
            ]
          }
        },
        "a0d62d16a41545579130cf91ac521fb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0530b7a82234b93878cbcb574e57aac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0664dde0885249ca8e3445d5af4fe425",
            "_dom_classes": [],
            "description": " 62%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 3125,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1939,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_29048a435a35494198acada14c53a514"
          }
        },
        "9966ae96912e4b46ba1e89a576e14316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_efcc4fcb61af418aa917015a2a53c5e4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1939/3125 [00:21&lt;00:02, 513.52it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1d206a08acac470d8a3cb93f3fd4259f"
          }
        },
        "0664dde0885249ca8e3445d5af4fe425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "29048a435a35494198acada14c53a514": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "efcc4fcb61af418aa917015a2a53c5e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1d206a08acac470d8a3cb93f3fd4259f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e398fa846bf47538ac15973d9f61f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c94f5bf7469b446ba25cbd677a824543",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_59cac78b06994b07bf2aa5bfbe550fcd",
              "IPY_MODEL_c4d1362522aa4ca7ba9778449fb5fc9e"
            ]
          }
        },
        "c94f5bf7469b446ba25cbd677a824543": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "59cac78b06994b07bf2aa5bfbe550fcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_536e700f0cb748baab1a591023c51378",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f6c0972ccce343b7859afac3d35d1a13"
          }
        },
        "c4d1362522aa4ca7ba9778449fb5fc9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cd8348219c804ef7ae956efc4917f453",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3accd2c438f548e0a370aaf3a3de98b2"
          }
        },
        "536e700f0cb748baab1a591023c51378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f6c0972ccce343b7859afac3d35d1a13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd8348219c804ef7ae956efc4917f453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3accd2c438f548e0a370aaf3a3de98b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_k91V7UYQl6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d43b925d-943a-434f-efcf-7f5b16eacfde"
      },
      "source": [
        "!pip install wandb\n",
        "!pip install tensorflow\n",
        "!pip install keras\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.datasets import fashion_mnist\n",
        "from tqdm.auto import tqdm\n",
        "import tensorflow as tf\n",
        "import wandb\n",
        "import pprint"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/ae/79374d2b875e638090600eaa2a423479865b7590c53fb78e8ccf6a64acb1/wandb-0.10.22-py2.py3-none-any.whl (2.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.0MB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/92/5a33be64990ba815364a8f2dd9e6f51de60d23dfddafb4f1fc5577d4dc64/sentry_sdk-1.0.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 41.0MB/s \n",
            "\u001b[?25hCollecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102kB 10.4MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163kB 29.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (54.0.0)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/d5/1e/6130925131f639b2acde0f7f18b73e33ce082ff2d90783c436b52040af5a/smmap-3.0.5-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=8c2bcce4e1b223ec00d0afc65c7982bc5e40afe1061a853d6e9f4e12d7c0c84c\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=7ba421ec0e9c24660b3ef6e4405222790d8ab18b166300414b379854fbcf8318\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: shortuuid, sentry-sdk, configparser, subprocess32, smmap, gitdb, GitPython, pathtools, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.14 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.5 pathtools-0.1.2 sentry-sdk-1.0.0 shortuuid-1.0.1 smmap-3.0.5 subprocess32-3.5.4 wandb-0.10.22\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow) (54.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.27.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjPTg70-YXjM"
      },
      "source": [
        "# Question 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESi2E1-zC6GV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0473f40-9957-4e07-c866-bdb7e83d95c1"
      },
      "source": [
        "def load_fashion_mnist(return_images=False):\n",
        "\n",
        "  (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "  train_shuffler = np.random.shuffle(np.arange(50000))\n",
        "  x_train, y_train = x_train[train_shuffler][0], y_train[train_shuffler][0]\n",
        "\n",
        "  test_shuffler = np.random.shuffle(np.arange(10000))\n",
        "  x_test, y_test = x_test[test_shuffler][0], y_test[test_shuffler][0]\n",
        "\n",
        "  x_train = np.array(x_train/255).astype('float32')\n",
        "  x_test = np.array(x_test/255).astype('float32')\n",
        "\n",
        "  x_train, x_val = x_train[:50000], x_train[50000:]\n",
        "  y_train, y_val = y_train[:50000], y_train[50000:]\n",
        "\n",
        "\n",
        "  if (return_images==False):\n",
        "    return {\n",
        "        'train': {\n",
        "            'X': x_train.reshape([50000, 784]),\n",
        "            'Y': y_train.reshape([50000])\n",
        "        },\n",
        "        'val': {\n",
        "            'X': x_val.reshape([10000, 784]),\n",
        "            'Y': y_val.reshape([10000])\n",
        "        },\n",
        "        'test': {\n",
        "            'X': x_test.reshape([10000, 784]),\n",
        "            'Y': y_test.reshape([10000])\n",
        "        }\n",
        "  }\n",
        "\n",
        "  else :\n",
        "    return {\n",
        "      'train': {\n",
        "          \t'X': x_train,\n",
        "          \t'Y': y_train\n",
        "      },\n",
        "      'val': {\n",
        "            'X': x_val,\n",
        "            'Y': y_val\n",
        "      },\n",
        "      'test': {\n",
        "            'X': x_test,\n",
        "            'Y': y_test\n",
        "      }\n",
        "    }\n",
        "\n",
        "\n",
        "data = load_fashion_mnist()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr-EXaU4oiZ_"
      },
      "source": [
        "# Question 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23nXB0VBojt0"
      },
      "source": [
        "class neural_network:\n",
        "\n",
        "  # constructor function - initializes weights\n",
        "  def __init__(self, dict_layers, initializer):\n",
        "\n",
        "    self.weights_list = []\n",
        "    self.biases_list = []\n",
        "    self.dict_layers= dict_layers\n",
        "\n",
        "    self.weights_list, self.biases_list = wandb_initializer(dict_layers, self.weights_list, self.biases_list, initializer)\n",
        "\n",
        "  # function to compute forward propogation\n",
        "  def forward_prop(self, W, b, X, Y, activation_func):\n",
        "\n",
        "    A = []\n",
        "    H = []\n",
        "    \n",
        "    H_pre = X\n",
        "    \n",
        "    L = self.dict_layers['num_hidden_layers']\n",
        "\n",
        "    for i in range(L) :\n",
        "      A.append(W[i] @ H_pre + b[i])\n",
        "      H_pre = getattr(activation, activation_func)(A[i])\n",
        "      H.append(H_pre)\n",
        "    \n",
        "    A.append(W[L] @ H_pre + b[L])\n",
        "    \n",
        "    Y_hat = activation.softmax(A[L])\n",
        "    \n",
        "    return {\n",
        "        'A' : A,\n",
        "        'H' : H,\n",
        "        'Y_hat' : Y_hat\n",
        "    }\n",
        "\n",
        "  # helper function to perform forward propogation \n",
        "  def self_forward_prop(self, X, Y, activation_func) :\n",
        "\n",
        "    temp = self.forward_prop(self.weights_list,self.biases_list, X, Y, activation_func)\n",
        "    return temp\n",
        "\n",
        "  # function to perform backward propogration\n",
        "  def back_prop(self, W, b, A, H, Y_hat, X, Y,activation_func):\n",
        "\n",
        "    batch_size = len(Y)\n",
        "    \n",
        "    del_w = []\n",
        "    del_b = []\n",
        "    L = self.dict_layers['num_hidden_layers']\n",
        "    \n",
        "    E = np.zeros(Y_hat.shape)\n",
        "    E[Y,np.arange(batch_size)] = 1\n",
        "    \n",
        "    grad_A = -(E - Y_hat)\n",
        "\n",
        "    for i in range(L,-1,-1) :\n",
        "\n",
        "      temp1 = grad_A.reshape(-1,batch_size)\n",
        "      \n",
        "      if i==0 :\n",
        "        temp2 = X.T\n",
        "      else :\n",
        "        temp2 = H[i-1].reshape((batch_size ,-1))\n",
        "\n",
        "      del_w.append(temp1 @ temp2)\n",
        "      del_b.append(grad_A)\n",
        "\n",
        "      if(i!=0) :\n",
        "        grad_H = W[i].T @ grad_A      \n",
        "        grad_A = grad_H * getattr(activation,activation_func+'_der')(H[i-1])\n",
        "\n",
        "    for j in range(len(del_b)) :\n",
        "       del_b[j] = np.sum(del_b[j],axis=1)\n",
        "\n",
        "    return {\n",
        "        'dw' : del_w,\n",
        "        'db' : del_b\n",
        "    }\n",
        "\n",
        "  # helper function to perform backward propogation\n",
        "  def self_back_prop(self, A, H, Y_hat, X, Y,activation_func) :\n",
        "    temp = self.back_prop(self.weights_list,self.biases_list, A, H, Y_hat, X, Y, activation_func)\n",
        "    return temp\n",
        "\n",
        "  #  function to compute gradient\n",
        "  def grad_wandb(self, W, b, X, Y,activation_func):\n",
        "\n",
        "    X = X.T.reshape((784,-1))\n",
        "    \n",
        "    temp = self.forward_prop(W, b, X, Y, activation_func)\n",
        "    temp2 = self.back_prop(W, b, temp['A'], temp['H'], temp['Y_hat'], X, Y, activation_func)\n",
        "\n",
        "    return {\n",
        "        'dw' : temp2['dw'],\n",
        "        'db' : temp2['db']\n",
        "    }\n",
        "\n",
        "  # helper function to compute gradient\n",
        "  def self_grad_wandb(self, X, Y, activation_func) :\n",
        "    temp = self.grad_wandb(self.weights_list, self.biases_list, X, Y,activation_func)\n",
        "    return temp\n",
        "\n",
        "  # function to compute predictions\n",
        "  def predict(self, X, activation_func):\n",
        "    X = X.T.reshape((784,-1))\n",
        "    temp = self.forward_prop(self.weights_list,self.biases_list, X, 0, activation_func)\n",
        "    return {\n",
        "      'Y' : np.argmax(temp['Y_hat'],axis=0),\n",
        "      'Y_hat' : temp['Y_hat']\n",
        "    }\n",
        "\n",
        "  # function to update weights and biases\n",
        "  def update_vals(self, dw, db, wd) :\n",
        "    L = len(self.weights_list)\n",
        "    for i in range(L) :\n",
        "      # print('dw['+str(L-i-1)+']',dw[L-i-1])\n",
        "      self.weights_list[i] =self.weights_list[i] - dw[L-i-1].reshape(self.weights_list[i].shape) - wd * self.weights_list[i]\n",
        "\n",
        "    for i in range(len(self.biases_list)) :\n",
        "      # print('db['+str(L-i-1)+']',db[L-i-1])\n",
        "      self.biases_list[i] =self.biases_list[i] - db[L-i-1].reshape(self.biases_list[i].shape)  \n",
        "##################################################################################\n",
        "class activation:\n",
        "  \n",
        "  @staticmethod\n",
        "  def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "  \n",
        "  @staticmethod\n",
        "  def relu(z):\n",
        "    return (z>0) * z\n",
        "\n",
        "  @staticmethod\n",
        "  def tanh(z):\n",
        "    return np.tanh(z)\n",
        "\n",
        "  @staticmethod\n",
        "  def sigmoid_der(z) :\n",
        "    return z * (1-z)\n",
        "  \n",
        "  @staticmethod\n",
        "  def relu_der(z) :\n",
        "    return (z>0)\n",
        "\n",
        "  @staticmethod\n",
        "  def tanh_der(z):\n",
        "    return 1 - z*z\n",
        "\n",
        "  @staticmethod\n",
        "  def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / np.sum(e_x,axis=0)\n",
        "    #return np.array(tf.nn.softmax(np.array(x)))\n",
        "##################################################################################\n",
        "def set_nn_shape(verbose=True, num_hidden_layers=-1, hidden_layer_size=-1):\n",
        "\n",
        "  input_layer_size = 784\n",
        "  hidden_layer_size = hidden_layer_size\n",
        "  num_hidden_layers = num_hidden_layers\n",
        "  output_layer_size = 10\n",
        "  \n",
        "  # input_layer_size = 3\n",
        "  # hidden_layer_size = hidden_layer_size\n",
        "  # num_hidden_layers = num_hidden_layers\n",
        "  # output_layer_size = 2\n",
        "  if (verbose):\n",
        "    print(\"\\nNumber Of Hidden Layers:\")\n",
        "    num_hidden_layers = int(input())\n",
        "\n",
        "    print(\"\\nSize Of Each Hidden Layer:\")\n",
        "    hidden_layer_size = int(input())\n",
        "\n",
        "    print(f\"\\nThe Neural Network Has {num_hidden_layers+2} Layers In Total!\")\n",
        "  \n",
        "  return {\"input_layer_size\": input_layer_size, \"hidden_layer_size\": hidden_layer_size, \"output_layer_size\": output_layer_size, \"num_hidden_layers\": num_hidden_layers}\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIFMpZQNItG3"
      },
      "source": [
        "def wandb_initializer(nn_shape, weights_list, biases_list, type='random', mu = 0, sigma = 1):\n",
        "  \n",
        "  # random initialization\n",
        "  if (type=='random'):\n",
        "    print('Random')\n",
        "    initializer = tf.keras.initializers.TruncatedNormal(mean=mu, stddev=sigma)\n",
        "  # xavier initialization\n",
        "  elif (type=='xavier'):\n",
        "    print('Xavier')\n",
        "    initializer = tf.keras.initializers.GlorotNormal()\n",
        "\n",
        "  weights_list.append(initializer(shape=(nn_shape['hidden_layer_size'], nn_shape['input_layer_size'])).numpy())\n",
        "  biases_list.append(initializer(shape=(nn_shape['hidden_layer_size'], 1)).numpy())\n",
        "  for i in range(nn_shape['num_hidden_layers'] - 1):\n",
        "    weights_list.append(initializer(shape=(nn_shape['hidden_layer_size'], nn_shape['hidden_layer_size'])).numpy())\n",
        "    biases_list.append(initializer(shape=(nn_shape['hidden_layer_size'], 1)).numpy())\n",
        "\n",
        "  weights_list.append(initializer(shape=(nn_shape['output_layer_size'], nn_shape['hidden_layer_size'])).numpy())\n",
        "  biases_list.append(initializer(shape=(nn_shape['output_layer_size'], 1)).numpy())\n",
        "\n",
        "  return weights_list, biases_list"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVpF16BtXqB_"
      },
      "source": [
        "class optimizer:\n",
        "\n",
        "  @staticmethod\n",
        "  def sgd(network, data, config):\n",
        "\n",
        "    # num_hidden_layers, hidden_layers_size = config['num_hidden_layers'], config['hidden_layer_size']\n",
        "    num_epochs, batch_size = config['num_epochs'], config['batch_size']\n",
        "    eta, lambda_ = config['lr'], config['weight_decay']\n",
        "    initializer, activation_func = config['weights_initializer'], config['activation']\n",
        " \n",
        "    ### google the getattr function - eg: getattr(activation, 'relu')(junk) is same as activation.relu(junk)\n",
        "    X_train, Y_train = data['train']['X'], data['train']['Y']\n",
        "    num_examples = len(X_train)\n",
        "\n",
        "    for i in range(num_epochs):\n",
        "      for k in tqdm(range(0, len(X_train), batch_size)) :\n",
        "        X = X_train[k: k+batch_size]\n",
        "        Y = Y_train[k: k+batch_size]\n",
        "        temp = network.self_grad_wandb(X, Y, activation_func)         \n",
        "        dw = temp['dw']\n",
        "        db = temp['db']\n",
        "        for dd in dw :\n",
        "          dd*= eta\n",
        "        for dd in db :\n",
        "          dd*=eta\n",
        "\n",
        "        network.update_vals(dw, db, lambda_)\n",
        "    \n",
        "      report = run_callback(network, data, config) \n",
        "        \n",
        "      wandb.log({\n",
        "            'batch_size': config.batch_size, \n",
        "            'val_loss' : report['loss']['val'], \n",
        "            'train_loss': report['loss']['train'],\n",
        "            'train_acc': report['accuracy']['train'],\n",
        "            'val_acc': report['accuracy']['val']  \n",
        "      }) \n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def momentum(network, data, config,gamma = 0.9) :\n",
        "    num_epochs, batch_size = config['num_epochs'], config['batch_size']\n",
        "    eta, lambda_ = config['lr'], config['weight_decay']\n",
        "    initializer, activation_func = config['weights_initializer'], config['activation']\n",
        "    \n",
        "    ### google the getattr function - eg: getattr(activation, 'relu')(junk) is same as activation.relu(junk)\n",
        "    X_train, Y_train = data['train']['X'], data['train']['Y']\n",
        "    num_examples = len(X_train)\n",
        "\n",
        "    nn_shape = set_nn_shape(False, config['num_hidden_layers'], config['hidden_layer_size'])\n",
        "    dw, db = wandb_initializer(nn_shape, [], [], 'random', 0, 0)\n",
        "\n",
        "    dw.reverse()\n",
        "    db.reverse()\n",
        "\n",
        "    for j in range(len(db)) :\n",
        "      db[j] = db[j].flatten()\n",
        "\n",
        "    for i in range(num_epochs) :\n",
        "      for k in tqdm(range(0, len(X_train), batch_size)) :\n",
        "        X = X_train[k:k+batch_size]\n",
        "        Y = Y_train[k:k+batch_size]\n",
        "        temp = network.self_grad_wandb(X,Y,activation_func)       \n",
        "        for j in range(len(dw)) :\n",
        "          dw[j] += eta*temp['dw'][j]\n",
        "          db[j] += eta*temp['db'][j]\n",
        "\n",
        "        network.update_vals(dw,db, lambda_)\n",
        "        for dd in db :\n",
        "          dd*=gamma\n",
        "        for dd in dw :\n",
        "          dd*=gamma\n",
        "\n",
        "      report = run_callback(network, data, config) \n",
        "        \n",
        "      wandb.log({\n",
        "            'batch_size': config.batch_size, \n",
        "            'val_loss' : report['loss']['val'], \n",
        "            'train_loss': report['loss']['train'],\n",
        "            'train_acc': report['accuracy']['train'],\n",
        "            'val_acc': report['accuracy']['val']  \n",
        "      }) \n",
        "        \n",
        "\n",
        "\n",
        "  \n",
        "  @staticmethod\n",
        "  def NAG(network, data, config,gamma = 0.9) :\n",
        "    num_epochs, batch_size = config['num_epochs'], config['batch_size']\n",
        "    eta, lambda_ = config['lr'], config['weight_decay']\n",
        "    initializer, activation_func = config['weights_initializer'], config['activation']\n",
        "    ### google the getattr function - eg: getattr(activation, 'relu')(junk) is same as activation.relu(junk)\n",
        "    X_train, Y_train = data['train']['X'], data['train']['Y']\n",
        "    num_examples = len(X_train)\n",
        "\n",
        "    nn_shape = set_nn_shape(False, config['num_hidden_layers'], config['hidden_layer_size'])\n",
        "    dw, db = wandb_initializer(nn_shape, [], [], 'random', 0, 0)\n",
        "\n",
        "    dw.reverse()\n",
        "    db.reverse()\n",
        "\n",
        "    for j in range(len(db)) :\n",
        "      db[j] = db[j].flatten()\n",
        "\n",
        "    for i in range(num_epochs) :\n",
        "      for k in tqdm(range(0, len(X_train), batch_size)) :\n",
        "        X = X_train[k:k+batch_size]\n",
        "        Y = Y_train[k:k+batch_size]\n",
        "        temp = network.self_grad_wandb(X,Y,activation_func)  \n",
        "\n",
        "        for j in range(len(dw)) :\n",
        "          dw[j] += eta*temp['dw'][j]\n",
        "          db[j] += eta*temp['db'][j]\n",
        "\n",
        "        network.update_vals(dw,db, 0)\n",
        "        for dd in db :\n",
        "          dd*=gamma\n",
        "        for dd in dw :\n",
        "          dd*=gamma\n",
        "        network.update_vals(dw,db, 0)\n",
        "\n",
        "      report = run_callback(network, data, config) \n",
        "        \n",
        "      wandb.log({\n",
        "            'batch_size': config.batch_size, \n",
        "            'val_loss' : report['loss']['val'], \n",
        "            'train_loss': report['loss']['train'],\n",
        "            'train_acc': report['accuracy']['train'],\n",
        "            'val_acc': report['accuracy']['val']  \n",
        "      }) \n",
        "\n",
        "  @staticmethod\n",
        "  def RMSprop(network, data, config,beta = 0.9,epsilon = 1e-4) :\n",
        "    \n",
        "    num_epochs, batch_size = config['num_epochs'], config['batch_size']\n",
        "    eta, lambda_ = config['lr'], config['weight_decay']\n",
        "    initializer, activation_func = config['weights_initializer'], config['activation']\n",
        "    \n",
        "    ### google the getattr function - eg: getattr(activation, 'relu')(junk) is same as activation.relu(junk)\n",
        "    X_train, Y_train = data['train']['X'], data['train']['Y']\n",
        "    num_examples = len(X_train)\n",
        "\n",
        "    nn_shape = set_nn_shape(False, config['num_hidden_layers'], config['hidden_layer_size'])\n",
        "    v_dw, v_db = wandb_initializer(nn_shape, [], [], 'random', 0, 0)\n",
        "\n",
        "    v_dw.reverse()\n",
        "    v_db.reverse()\n",
        "\n",
        "    for j in range(len(v_db)) :\n",
        "      v_db[j] = v_db[j].flatten()\n",
        "\n",
        "    for i in range(num_epochs) :\n",
        "      dw = []\n",
        "      db = []\n",
        "      for k in tqdm(range(0, len(X_train), batch_size)) :\n",
        "        X = X_train[k:k+batch_size]\n",
        "        Y = Y_train[k:k+batch_size]\n",
        "        temp = network.self_grad_wandb(X,Y,activation_func)  \n",
        "\n",
        "        dw = temp['dw']\n",
        "        db = temp['db']\n",
        "\n",
        "        for j in range(len(dw)) :\n",
        "          v_dw[j] *= beta\n",
        "          v_dw[j] += (1-beta)*(dw[j]**2) \n",
        "          dw[j] *= eta/np.sqrt(v_dw[j]+epsilon)\n",
        "          v_db[j] *= beta\n",
        "          v_db[j] += (1-beta)*(db[j]**2) \n",
        "          db[j] *= eta/np.sqrt(v_db[j]+epsilon)\n",
        "\n",
        "        network.update_vals(dw,db, lambda_)\n",
        "\n",
        "      report = run_callback(network, data, config) \n",
        "        \n",
        "      wandb.log({\n",
        "            'batch_size': config.batch_size, \n",
        "            'val_loss' : report['loss']['val'], \n",
        "            'train_loss': report['loss']['train'],\n",
        "            'train_acc': report['accuracy']['train'],\n",
        "            'val_acc': report['accuracy']['val']  \n",
        "      }) \n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def adam(network, data, config, beta1=0.9, beta2=0.999, epsilon=1e-4):\n",
        "\n",
        "    # num_hidden_layers, hidden_layers_size = config['num_hidden_layers'], config['hidden_layer_size']\n",
        "    num_epochs, batch_size = config['num_epochs'], config['batch_size']\n",
        "    eta, lambda_ = config['lr'], config['weight_decay']\n",
        "    initializer, activation_func = config['weights_initializer'], config['activation']\n",
        " \n",
        "    ### google the getattr function - eg: getattr(activation, 'relu')(junk) is same as activation.relu(junk)\n",
        "    X_train, Y_train = data['train']['X'], data['train']['Y']\n",
        "    num_examples = len(X_train)\n",
        "    nn_shape = set_nn_shape(False, config['num_hidden_layers'], config['hidden_layer_size'])\n",
        "\n",
        "    m_w, m_b = wandb_initializer(nn_shape, [], [], 'random', 0, 0)\n",
        "    v_w, v_b = wandb_initializer(nn_shape, [], [], 'random', 0, 0)\n",
        "\n",
        "    m_w.reverse()\n",
        "    m_b.reverse()\n",
        "    v_w.reverse()\n",
        "    v_b.reverse()\n",
        "    for j in range(len(m_b)):\n",
        "      m_b[j], v_b[j] = m_b[j].flatten(), v_b[j].flatten() \n",
        "    # print('Checkpoint 1')\n",
        "    t = 0\n",
        "    for i in range(num_epochs):\n",
        "      for k in tqdm(range(0, len(X_train), batch_size)) :\n",
        "        \n",
        "        t += 1\n",
        "        \n",
        "        X = X_train[k: k+batch_size]\n",
        "        Y = Y_train[k: k+batch_size]\n",
        "        \n",
        "        temp = network.self_grad_wandb(X, Y, activation_func)\n",
        "        # print('Checkpoint 2')  \n",
        "        dw = temp['dw']\n",
        "        db = temp['db']\n",
        "        \n",
        "        for j in range(len(dw)):\n",
        "          # print(db[j].shape, m_b[j].shape, v_b[j].shape)\n",
        "          m_w[j] = beta1 * m_w[j] + (1 - beta1) * dw[j]\n",
        "          # print('Checkpoint 2.5')\n",
        "          \n",
        "          m_b[j] = beta1 * m_b[j] + (1 - beta1) * db[j]\n",
        "          # print('Checkpoint 3')\n",
        "          v_w[j] = beta2 * v_w[j] + (1 - beta2) * dw[j] * dw[j]\n",
        "          v_b[j] = beta2 * v_b[j] + (1 - beta2) * db[j] * db[j]\n",
        "          # print('Checkpoint 4')\n",
        "                 \n",
        "          m_w[j] = m_w[j] *((1-beta1**int(t))/ (1-beta1**int(t+1)))\n",
        "          m_b[j] = m_b[j] *((1-beta1**int(t))/ (1-beta1**int(t+1)))\n",
        "          # # print('Checkpoint 5')\n",
        "          v_w[j] = v_w[j]*((1-beta2**int(t))/ (1-beta2**int(t+1)))\n",
        "          v_b[j] = v_b[j]*((1-beta2**int(t))/ (1-beta2**int(t+1)))\n",
        "          # print('Checkpoint 6')\n",
        "          \n",
        "          dw[j] = eta * m_w[j] / (epsilon + np.sqrt( v_w[j]))\n",
        "          db[j] = eta * m_b[j] / ( epsilon + np.sqrt(v_b[j]))\n",
        "\n",
        "          # print('Checkpoint 7')\n",
        "        \n",
        "        network.update_vals(dw, db, lambda_)\n",
        "        \n",
        "      report = run_callback(network, data, config) \n",
        "        \n",
        "      wandb.log({\n",
        "            'batch_size': config.batch_size, \n",
        "            'val_loss' : report['loss']['val'], \n",
        "            'train_loss': report['loss']['train'],\n",
        "            'train_acc': report['accuracy']['train'],\n",
        "            'val_acc': report['accuracy']['val']  \n",
        "      })\n",
        "\n",
        "    \n",
        "  @staticmethod\n",
        "  def nadam(network, data, config, beta1=0.9, beta2=0.999, epsilon=1e-4):\n",
        "\n",
        "    # num_hidden_layers, hidden_layers_size = config['num_hidden_layers'], config['hidden_layer_size']\n",
        "    num_epochs, batch_size = config['num_epochs'], config['batch_size']\n",
        "    eta, lambda_ = config['lr'], config['weight_decay']\n",
        "    initializer, activation_func = config['weights_initializer'], config['activation']\n",
        " \n",
        "    ### google the getattr function - eg: getattr(activation, 'relu')(junk) is same as activation.relu(junk)\n",
        "    X_train, Y_train = data['train']['X'], data['train']['Y']\n",
        "    num_examples = len(X_train)\n",
        "    # print(num_hidden_layers, hidden_layers_size)\n",
        "    nn_shape = set_nn_shape(False, config['num_hidden_layers'], config['hidden_layer_size'])\n",
        "\n",
        "    m_w, m_b = wandb_initializer(nn_shape, [], [], 'random', 0, 0)\n",
        "    v_w, v_b = wandb_initializer(nn_shape, [], [], 'random', 0, 0)\n",
        "\n",
        "    m_w.reverse()\n",
        "    m_b.reverse()\n",
        "    v_w.reverse()\n",
        "    v_b.reverse()\n",
        "    for j in range(len(m_b)):\n",
        "      m_b[j], v_b[j] = m_b[j].flatten(), v_b[j].flatten() \n",
        "    # print('Checkpoint 1')\n",
        "    t = 0\n",
        "    for i in range(num_epochs):\n",
        "      for k in tqdm(range(0, len(X_train), batch_size)) :\n",
        "        \n",
        "        t += 1\n",
        "        \n",
        "        X = X_train[k: k+batch_size]\n",
        "        Y = Y_train[k: k+batch_size]\n",
        "        \n",
        "        temp = network.self_grad_wandb(X, Y, activation_func)\n",
        "        # print('Checkpoint 2')  \n",
        "        dw = temp['dw']\n",
        "        db = temp['db']\n",
        "        \n",
        "        for j in range(len(dw)):\n",
        "          # print(db[j].shape, m_b[j].shape, v_b[j].shape)\n",
        "          m_w[j] = beta1 * m_w[j] + (1 - beta1) * dw[j]\n",
        "          # print('Checkpoint 2.5')\n",
        "          \n",
        "          m_b[j] = beta1 * m_b[j] + (1 - beta1) * db[j]\n",
        "          # print('Checkpoint 3')\n",
        "          v_w[j] = beta2 * v_w[j] + (1 - beta2) * dw[j] * dw[j]\n",
        "          v_b[j] = beta2 * v_b[j] + (1 - beta2) * db[j] * db[j]\n",
        "          # print('Checkpoint 4')\n",
        "                 \n",
        "          m_w[j] = m_w[j] *((1-beta1**int(t))/ (1-beta1**int(t+1)))\n",
        "          m_b[j] = m_b[j] *((1-beta1**int(t))/ (1-beta1**int(t+1)))\n",
        "          # # print('Checkpoint 5')\n",
        "          v_w[j] = v_w[j]*((1-beta2**int(t))/ (1-beta2**int(t+1)))\n",
        "          v_b[j] = v_b[j]*((1-beta2**int(t))/ (1-beta2**int(t+1)))\n",
        "          # print('Checkpoint 6')\n",
        "          \n",
        "          dw[j] = eta * (beta1*m_w[j] + (1 - beta1)*dw[j]) / (epsilon + np.sqrt( v_w[j]))\n",
        "          db[j] = eta * (beta1*m_b[j] + (1 - beta1)*db[j]) / ( epsilon + np.sqrt(v_b[j]))\n",
        "\n",
        "          # print('Checkpoint 7')\n",
        "        \n",
        "        network.update_vals(dw, db, lambda_)\n",
        "        \n",
        "      report = run_callback(network, data, config) \n",
        "        \n",
        "      wandb.log({\n",
        "            'batch_size': config.batch_size, \n",
        "            'val_loss' : report['loss']['val'], \n",
        "            'train_loss': report['loss']['train'],\n",
        "            'train_acc': report['accuracy']['train'],\n",
        "            'val_acc': report['accuracy']['val']  \n",
        "      })"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKQ-oZvbLOWV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3ec1ca76-5373-485d-ade6-b1b275fd3557"
      },
      "source": [
        "'''\n",
        "# X = np.array([[1,1,2],[-1,2,3],[10,-67,43],[-5,45,-67]])\n",
        "# Y = np.array([1,0,1,0])\n",
        "# temp = solver.sgd(X,Y,100,1e-3)\n",
        "X=data['train']['X']\n",
        "# print(len(X))\n",
        "# print(X[0])\n",
        "Y = data['train']['Y']\n",
        "temp = solver.RMSprop(X,Y,100,0.001,0.9,32,1e-2)\n",
        "print(temp)\n",
        "'''"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# X = np.array([[1,1,2],[-1,2,3],[10,-67,43],[-5,45,-67]])\\n# Y = np.array([1,0,1,0])\\n# temp = solver.sgd(X,Y,100,1e-3)\\nX=data['train']['X']\\n# print(len(X))\\n# print(X[0])\\nY = data['train']['Y']\\ntemp = solver.RMSprop(X,Y,100,0.001,0.9,32,1e-2)\\nprint(temp)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKDlM0FUKutJ"
      },
      "source": [
        "def run_callback(network,data,config) :\n",
        "    \n",
        "    activation_func = config['activation']\n",
        "    \n",
        "    X_train = data['train']['X']\n",
        "    Y_train = data['train']['Y']\n",
        "\n",
        "    X_val = data['val']['X']\n",
        "    Y_val = data['val']['Y']\n",
        "\n",
        "    train_loss = 0\n",
        "    train_count = 0\n",
        "    train_sq_error = 0\n",
        "    \n",
        "    temp = network.predict(X_train,activation_func)\n",
        "    train_count = np.sum(temp['Y'].reshape(Y_train.shape)==Y_train)\n",
        "    \n",
        "    Y_pred = np.array(temp['Y_hat'].T)\n",
        "    train_loss = np.sum(-np.log(Y_pred[np.arange(len(X_train)),Y_train]))\n",
        "    E = np.zeros(Y_pred.shape)\n",
        "    E[np.arange(len(X_train)),Y_train] = 1\n",
        "    train_sq_error = np.sum((E-Y_pred)**2)\n",
        "\n",
        "    val_loss = 0\n",
        "    val_count = 0\n",
        "    val_sq_error = 0\n",
        "    \n",
        "    temp = network.predict(X_val, activation_func)\n",
        "    val_count = np.sum(temp['Y'].reshape(Y_val.shape)==Y_val)\n",
        "    \n",
        "    Y_pred = np.array(temp['Y_hat'].T)\n",
        "    val_loss = np.sum(-np.log(Y_pred[np.arange(len(X_val)),Y_val]))\n",
        "    E = np.zeros(Y_pred.shape)\n",
        "    E[np.arange(len(X_val)),Y_val] = 1\n",
        "    val_sq_error = np.sum((E-Y_pred)**2)\n",
        "\n",
        "    \n",
        "    '''\n",
        "    test_loss = 0\n",
        "    test_count = 0\n",
        "    test_sq_error = 0\n",
        "    for x,y in zip(X_test,Y_test) :\n",
        "        temp = network.predict(x,activation_func)\n",
        "        if temp['y'] == y :\n",
        "            test_count += 1\n",
        "        test_loss -= np.log(temp['y_hat'][y]) \n",
        "        temp['y_hat'][y] = 1 - temp['y_hat'][y]\n",
        "        test_sq_error += np.sum(np.dot(temp['y_hat'],temp['y_hat'])) \n",
        "    '''\n",
        "    \n",
        "    return  {\n",
        "        'loss': {\n",
        "            'train' : train_loss / len(X_train),\n",
        "            'val' : val_loss / len(X_val)\n",
        "        },\n",
        "        'accuracy': {\n",
        "            'train': train_count / len(X_train),\n",
        "            'val': val_count / len(X_val)\n",
        "        }\n",
        "        #'test' : np.array([test_sq_error,test_loss,test_count])/len(X_test)\n",
        "    }\n",
        "\n",
        "    \n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "Ypd2xySp_dYj",
        "outputId": "e0d98f03-a8c8-45a1-f758-0b04adb4bdc1"
      },
      "source": [
        "'''\n",
        "nn = set_nn_shape()\n",
        "network = neural_network(nn, 'random')\n",
        "#data1 = {'train' : {'X': np.array([[1,1,2],[-1,2,3],[10,-67,43],[-5,45,-67],[5,6,7]]), 'Y' : np.array([1,0,1,0,1]) },'val' : {'X': np.array([[1,1,1],[1,1,1],[1,1,1],[1,1,1],[1,1,1]]), 'Y' : np.array([0,1,3,2,1]) }}\n",
        "# need to change this bit later to accomodate other optimization functions\n",
        "\n",
        "config1 = {'num_epochs' : 5,'lr' : 1e-2,'optimizer': 'sgd', 'batch_size' : 32 , 'weights_initializer' : 'random' , 'weight_decay' : 0.001, 'activation' : 'sigmoid' }\n",
        "optimizer.sgd(network, data,config1 )\n",
        "\n",
        "# generating reports for the run\n",
        "report = run_callback(network, data, config1) \n",
        "\n",
        "print(report)\n",
        "'''"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nnn = set_nn_shape()\\nnetwork = neural_network(nn, 'random')\\n#data1 = {'train' : {'X': np.array([[1,1,2],[-1,2,3],[10,-67,43],[-5,45,-67],[5,6,7]]), 'Y' : np.array([1,0,1,0,1]) },'val' : {'X': np.array([[1,1,1],[1,1,1],[1,1,1],[1,1,1],[1,1,1]]), 'Y' : np.array([0,1,3,2,1]) }}\\n# need to change this bit later to accomodate other optimization functions\\n\\nconfig1 = {'num_epochs' : 5,'lr' : 1e-2,'optimizer': 'sgd', 'batch_size' : 32 , 'weights_initializer' : 'random' , 'weight_decay' : 0.001, 'activation' : 'sigmoid' }\\noptimizer.sgd(network, data,config1 )\\n\\n# generating reports for the run\\nreport = run_callback(network, data, config1) \\n\\nprint(report)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PBdDNBajeN6S",
        "outputId": "698f9707-0157-4fba-aeba-b89de6fdf424"
      },
      "source": [
        "'''\n",
        "# generating reports for the run\n",
        "report = run_callback(network, data, config1) \n",
        "print(report)\n",
        "'''"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# generating reports for the run\\nreport = run_callback(network, data, config1) \\nprint(report)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5bkB6Q6JS3R",
        "outputId": "0f6d1fa9-3570-4db4-c9a7-e489bc7982a2"
      },
      "source": [
        "activation.softmax(np.array([[0.7,0.5],[3,7]]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.09112296, 0.00150118],\n",
              "       [0.90887704, 0.99849882]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9IjksI6O6wE"
      },
      "source": [
        "sweep_config = {\n",
        "    'method': 'random',\n",
        "\n",
        "    'parameters': {\n",
        "        'num_epochs': {\n",
        "            'values': [5, 10]\n",
        "        },\n",
        "        'num_hidden_layers': {\n",
        "            'values': [3, 4, 5]\n",
        "        },\n",
        "        'hidden_layer_size': {\n",
        "            'values': [32, 64, 128]\n",
        "        },\n",
        "        'weight_decay': {\n",
        "            'values': [0, 0.0005, 0.05]\n",
        "        },\n",
        "        'lr': {\n",
        "            'values': [1e-3, 1e-4]\n",
        "        },\n",
        "        'optimizer': {\n",
        "            'values': ['sgd', 'momentum', 'NAG', 'RMSprop', 'adam', 'nadam']\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [16, 32, 64]\n",
        "        },\n",
        "        'weights_initializer': {\n",
        "            'values': ['random', 'xavier']\n",
        "        },\n",
        "        'activation': {\n",
        "            'values': ['sigmoid', 'tanh', 'relu']\n",
        "        }        \n",
        "    }\n",
        "}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7l-y_6YO6wE",
        "outputId": "7a589377-0221-400a-b3be-199698bc35ed"
      },
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project='test5')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: lghoy340\n",
            "Sweep URL: https://wandb.ai/ramkamal/test5/sweeps/lghoy340\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fhn-A6mcO6wF",
        "outputId": "231caa4e-8ac4-4f84-d9b7-60af5cc311db"
      },
      "source": [
        "pprint.pprint(sweep_config)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'method': 'random',\n",
            " 'parameters': {'activation': {'values': ['sigmoid', 'tanh', 'relu']},\n",
            "                'batch_size': {'values': [16, 32, 64]},\n",
            "                'hidden_layer_size': {'values': [32, 64, 128]},\n",
            "                'lr': {'values': [0.001, 0.0001]},\n",
            "                'num_epochs': {'values': [5, 10]},\n",
            "                'num_hidden_layers': {'values': [3, 4, 5]},\n",
            "                'optimizer': {'values': ['sgd',\n",
            "                                         'momentum',\n",
            "                                         'NAG',\n",
            "                                         'RMSprop',\n",
            "                                         'adam',\n",
            "                                         'nadam']},\n",
            "                'weight_decay': {'values': [0, 0.0005, 0.05]},\n",
            "                'weights_initializer': {'values': ['random', 'xavier']}}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qml5BFsMO6wF"
      },
      "source": [
        "class sweep_module:\n",
        "  @staticmethod\n",
        "  def train(config=None):\n",
        "\n",
        "    with wandb.init(config):\n",
        "      # print('Checkpoint 1')\n",
        "      config = wandb.config\n",
        "      # print('Checkpoint 2')\n",
        "      \n",
        "      nn_shape = set_nn_shape(False, config['num_hidden_layers'] , config['hidden_layer_size'])\n",
        "      \n",
        "      # print('Checkpoint 3')\n",
        "      \n",
        "      # print(nn_shape)\n",
        "      network = neural_network(nn_shape, config['weights_initializer'])\n",
        "      # print('Checkpoint 4')\n",
        "      \n",
        "      # need to change this bit later to accomodate other optimization functions\n",
        "      optimizer.nadam(network, data, config)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8sPRi_YktYY6",
        "outputId": "c0a2649c-aa11-4440-ab93-169225a20c11"
      },
      "source": [
        "sweep_id"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'lghoy340'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521,
          "referenced_widgets": [
            "ed91123207604a5a9f5e57c3eec30bc8",
            "a0d62d16a41545579130cf91ac521fb4",
            "f0530b7a82234b93878cbcb574e57aac",
            "9966ae96912e4b46ba1e89a576e14316",
            "0664dde0885249ca8e3445d5af4fe425",
            "29048a435a35494198acada14c53a514",
            "efcc4fcb61af418aa917015a2a53c5e4",
            "1d206a08acac470d8a3cb93f3fd4259f",
            "8e398fa846bf47538ac15973d9f61f52",
            "c94f5bf7469b446ba25cbd677a824543",
            "59cac78b06994b07bf2aa5bfbe550fcd",
            "c4d1362522aa4ca7ba9778449fb5fc9e",
            "536e700f0cb748baab1a591023c51378",
            "f6c0972ccce343b7859afac3d35d1a13",
            "cd8348219c804ef7ae956efc4917f453",
            "3accd2c438f548e0a370aaf3a3de98b2"
          ]
        },
        "id": "lCYYRxwNO6wF",
        "outputId": "abc5e331-f4dc-459c-b736-6f6f3d32dab1"
      },
      "source": [
        "# for logging the best model\n",
        "network_best = None\n",
        "val_acc_best = -1\n",
        "\n",
        "# performing the sweep\n",
        "wandb.agent(sweep_id, sweep_module.train)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ih1pryj9 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: sigmoid\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_hidden_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: momentum\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweights_initializer: random\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.22<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">olive-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/ramkamal/test5\" target=\"_blank\">https://wandb.ai/ramkamal/test5</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/ramkamal/test5/sweeps/lghoy340\" target=\"_blank\">https://wandb.ai/ramkamal/test5/sweeps/lghoy340</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/ramkamal/test5/runs/ih1pryj9\" target=\"_blank\">https://wandb.ai/ramkamal/test5/runs/ih1pryj9</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210314_074910-ih1pryj9</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Random\n",
            "Random\n",
            "Random\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed91123207604a5a9f5e57c3eec30bc8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=3125.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 770<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e398fa846bf47538ac15973d9f61f52",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4KTU83FO6wG"
      },
      "source": [
        "nn_shape = {'input_layer_size': 784, 'hidden_layer_size': 64, 'output_layer_size': 10, 'num_hidden_layers': 5}"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUns-LmFO6wG"
      },
      "source": [
        "init = 'random'"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY4ab_ELO6wH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bef29d5a-b999-4673-bfbe-f23cff0e3303"
      },
      "source": [
        "neural_network(nn_shape, init)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.neural_network at 0x7f0d505b5fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAVEzbsyO6wH"
      },
      "source": [
        "nn_shape = {'input_layer_size': 784, 'hidden_layer_size': 64, 'output_layer_size': 10, 'num_hidden_layers': 3}"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLIAvg5EodzD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e33c5ea-7739-4db2-ed1d-bbffac92ca13"
      },
      "source": [
        "a, b = wandb_initializer(nn_shape,\n",
        "                  [],\n",
        "                  [],\n",
        "                  'random',\n",
        "                  0,\n",
        "                  0)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKpkfVErolKn"
      },
      "source": [
        "a.reverse()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2AR3FRbo3hJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66c07c36-feaf-4e19-f0df-52835244a2a2"
      },
      "source": [
        "help(wandb.agent)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function agent in module wandb.wandb_agent:\n",
            "\n",
            "agent(sweep_id, function=None, entity=None, project=None, count=None)\n",
            "    Generic agent entrypoint, used for CLI or jupyter.\n",
            "    \n",
            "    Will run a function or program with configuration parameters specified\n",
            "    by server.\n",
            "    \n",
            "    Arguments:\n",
            "        sweep_id: (dict) Sweep ID generated by CLI or sweep API\n",
            "        function: (func, optional) A function to call instead of the \"program\"\n",
            "            specifed in the config.\n",
            "        entity: (str, optional) W&B Entity\n",
            "        project: (str, optional) W&B Project\n",
            "        count: (int, optional) the number of trials to run.\n",
            "    \n",
            "    Examples:\n",
            "        Run a sample sweep over a function:\n",
            "        ```\n",
            "        def train():\n",
            "            with wandb.init() as run:\n",
            "                print(\"config:\", dict(run.config))\n",
            "                for epoch in range(35):\n",
            "                    print(\"running\", epoch)\n",
            "                    wandb.log({\"metric\": run.config.param1, \"epoch\": epoch})\n",
            "                    time.sleep(1)\n",
            "    \n",
            "        wandb.agent(sweep_id, function=train)\n",
            "        ```\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX3FouHNtQNO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}