{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of DL Assignment 1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ef6d7a60b55e480483bdeacbb34f394e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_73e6141c6ebe42b49483e6737b17a79f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bc73a7879d7a4542bbfa8813becb427b",
              "IPY_MODEL_86479d64148148548a7001d69c2d3e5b"
            ]
          }
        },
        "73e6141c6ebe42b49483e6737b17a79f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc73a7879d7a4542bbfa8813becb427b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0a363262c1194105a339a3d0d90efcf1",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 16667,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 16667,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b4d5d37e88b4293ad5af537c74c37a8"
          }
        },
        "86479d64148148548a7001d69c2d3e5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c1374703a9e54c558370ce4dbade4b62",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 16667/16667 [00:25&lt;00:00, 650.96it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6e07dcd3773a4674a930978ecca429f3"
          }
        },
        "0a363262c1194105a339a3d0d90efcf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b4d5d37e88b4293ad5af537c74c37a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1374703a9e54c558370ce4dbade4b62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6e07dcd3773a4674a930978ecca429f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_k91V7UYQl6"
      },
      "source": [
        "import keras\r\n",
        "import numpy as np\r\n",
        "from keras.datasets import fashion_mnist\r\n",
        "from tqdm.auto import tqdm"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7QqJEYg-ko5",
        "outputId": "a37fff9e-9b2e-495a-ad95-5de616890e4f"
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.1)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow) (54.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.27.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjPTg70-YXjM"
      },
      "source": [
        "# Question 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESi2E1-zC6GV"
      },
      "source": [
        "def load_fashion_mnist(return_images=False):\r\n",
        "\r\n",
        "  (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\r\n",
        "\r\n",
        "  train_shuffler = np.random.shuffle(np.arange(50000))\r\n",
        "  x_train, y_train = x_train[train_shuffler][0], y_train[train_shuffler][0]\r\n",
        "\r\n",
        "  test_shuffler = np.random.shuffle(np.arange(10000))\r\n",
        "  x_test, y_test = x_test[test_shuffler][0], y_test[test_shuffler][0]\r\n",
        "\r\n",
        "  x_train = np.array(x_train/255).astype('float32')\r\n",
        "  x_test = np.array(x_test/255).astype('float32')\r\n",
        "\r\n",
        "  x_train, x_val = x_train[:50000], x_train[50000:]\r\n",
        "  y_train, y_val = y_train[:50000], y_train[50000:]\r\n",
        "\r\n",
        "\r\n",
        "  if (return_images==False):\r\n",
        "    return {\r\n",
        "        'train': {\r\n",
        "            'X': x_train.reshape([50000, 784]),\r\n",
        "            'Y': y_train.reshape([50000])\r\n",
        "        },\r\n",
        "        'val': {\r\n",
        "            'X': x_val.reshape([10000, 784]),\r\n",
        "            'Y': y_val.reshape([10000])\r\n",
        "        },\r\n",
        "        'test': {\r\n",
        "            'X': x_test.reshape([10000, 784]),\r\n",
        "            'Y': y_test.reshape([10000])\r\n",
        "        }\r\n",
        "  }\r\n",
        "\r\n",
        "  else :\r\n",
        "    return {\r\n",
        "      'train': {\r\n",
        "          \t'X': x_train,\r\n",
        "          \t'Y': y_train\r\n",
        "      },\r\n",
        "      'val': {\r\n",
        "            'X': x_val,\r\n",
        "            'Y': y_val\r\n",
        "      },\r\n",
        "      'test': {\r\n",
        "            'X': x_test,\r\n",
        "            'Y': y_test\r\n",
        "      }\r\n",
        "    }\r\n",
        "\r\n",
        "\r\n",
        "data = load_fashion_mnist()"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr-EXaU4oiZ_"
      },
      "source": [
        "# Question 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23nXB0VBojt0"
      },
      "source": [
        "class neural_network:\r\n",
        "\r\n",
        "  # constructor function - initializes weights\r\n",
        "  def __init__(self, dict_layers, initializer):\r\n",
        "\r\n",
        "    self.weights_list = []\r\n",
        "    self.biases_list = []\r\n",
        "    self.dict_layers= dict_layers\r\n",
        "\r\n",
        "    self.weights_list, self.biases_list = wandb_initializer(dict_layers, self.weights_list, self.biases_list, initializer)\r\n",
        "\r\n",
        "  # function to compute forward propogation\r\n",
        "  def forward_prop(self, W, b, X, Y, activation_func):\r\n",
        "\r\n",
        "    A = []\r\n",
        "    H = []\r\n",
        "    \r\n",
        "    H_pre = X\r\n",
        "    \r\n",
        "    L = self.dict_layers['num_hidden_layers']\r\n",
        "\r\n",
        "    for i in range(L) :\r\n",
        "      A.append(W[i] @ H_pre + b[i])\r\n",
        "      H_pre = getattr(activation, activation_func)(A[i])\r\n",
        "      H.append(H_pre)\r\n",
        "    \r\n",
        "    A.append(W[L] @ H_pre + b[L])\r\n",
        "    \r\n",
        "    Y_hat = activation.softmax(A[L])\r\n",
        "    \r\n",
        "    return {\r\n",
        "        'A' : A,\r\n",
        "        'H' : H,\r\n",
        "        'Y_hat' : Y_hat\r\n",
        "    }\r\n",
        "\r\n",
        "  def self_forward_prop(self, X, Y, activation_func) :\r\n",
        "\r\n",
        "    temp = self.forward_prop(self.weights_list,self.biases_list, X, Y, activation_func)\r\n",
        "    return temp\r\n",
        "\r\n",
        "  def back_prop(self, W, b, A, H, Y_hat, X, Y,activation_func):\r\n",
        "\r\n",
        "    batch_size = len(Y)\r\n",
        "    \r\n",
        "    del_w = []\r\n",
        "    del_b = []\r\n",
        "\r\n",
        "    L = self.dict_layers['num_hidden_layers']\r\n",
        "    \r\n",
        "    E = np.zeros(Y_hat.shape)\r\n",
        "    \r\n",
        "    # E[np.arange(Y.size), Y] = 1\r\n",
        "    for j in range(len(Y)):\r\n",
        "        E[int(Y[j])][j] = 1\r\n",
        "    \r\n",
        "    # what shape do you need y_hat and e to be in? Column or row vector?\r\n",
        "    grad_A = -(E - Y_hat)\r\n",
        "    #print('grad_a', grad_a.shape)\r\n",
        "\r\n",
        "    for i in range(L,-1,-1) :\r\n",
        "\r\n",
        "      temp1 = grad_A.reshape(-1,batch_size)\r\n",
        "      if i==0 :\r\n",
        "        temp2 = X.reshape((batch_size ,-1))\r\n",
        "      else :\r\n",
        "        temp2 = H[i-1].reshape((batch_size ,-1))\r\n",
        "\r\n",
        "      del_w.append(temp1 @ temp2)\r\n",
        "      del_b.append(grad_A)\r\n",
        "\r\n",
        "      if(i!=0) :\r\n",
        "        grad_H = W[i].T @ grad_A      \r\n",
        "        act = activation()\r\n",
        "        grad_A = grad_H * getattr(act,activation_func+'_der')(H[i-1])\r\n",
        "\r\n",
        "    return {\r\n",
        "        'dw' : del_w,\r\n",
        "        'db' : del_b\r\n",
        "    }\r\n",
        "\r\n",
        "  def self_back_prop(self, A, H, Y_hat, X, Y,activation_func) :\r\n",
        "    temp = self.back_prop(self.weights_list,self.biases_list, A, H, Y_hat, X, Y, activation_func)\r\n",
        "    return temp\r\n",
        "\r\n",
        "  def grad_wandb(self, W, b, X, Y,activation_func):\r\n",
        "\r\n",
        "    X = X.T.reshape((784,-1))\r\n",
        "    Y = Y.reshape((-1, 1))\r\n",
        "    \r\n",
        "    temp = self.forward_prop(W, b, X, Y, activation_func)\r\n",
        "    temp2 = self.back_prop(W, b, temp['A'], temp['H'], temp['Y_hat'], X, Y, activation_func)\r\n",
        "\r\n",
        "    return {\r\n",
        "        'dw' : temp2['dw'],\r\n",
        "        'db' : temp2['db']\r\n",
        "    }\r\n",
        "\r\n",
        "  def self_grad_wandb(self, X, Y, activation_func) :\r\n",
        "    temp = self.grad_wandb(self.weights_list, self.biases_list, X, Y,activation_func)\r\n",
        "    return temp\r\n",
        "\r\n",
        "  def predict(self, X, activation_func):\r\n",
        "    temp = self.forward_prop(self.weights_list,self.biases_list, X, 0, activation_func)\r\n",
        "    return {\r\n",
        "      'y' : np.argmax(temp['Y_hat']),\r\n",
        "      'y_hat' : temp['Y_hat']\r\n",
        "    }\r\n",
        "\r\n",
        "  def update_vals(self,dw,db) :\r\n",
        "    L = len(self.weights_list)\r\n",
        "    for i in range(L) :\r\n",
        "      self.weights_list[i] =self.weights_list[i] - dw[L-i-1].reshape(self.weights_list[i].shape)\r\n",
        "\r\n",
        "    for i in range(len(self.biases_list)) :\r\n",
        "      self.biases_list[i] =self.biases_list[i] - db[L-i-1].reshape(self.biases_list[i].shape)\r\n",
        "##################################################################################\r\n",
        "class activation:\r\n",
        "  \r\n",
        "  @staticmethod\r\n",
        "  def sigmoid(z):\r\n",
        "    z = np.array(z,dtype=np.longdouble)\r\n",
        "    return 1 / (1 + np.exp(-z))\r\n",
        "  \r\n",
        "  @staticmethod\r\n",
        "  def relu(z):\r\n",
        "    return (z>0) * z\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def tanh(z):\r\n",
        "    return np.tanh(z)\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def sigmoid_der(z) :\r\n",
        "    return z * (1-z)\r\n",
        "  \r\n",
        "  @staticmethod\r\n",
        "  def relu_der(z) :\r\n",
        "    return (z>0)\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def tanh_der(z):\r\n",
        "    return 1 - z*z\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def softmax(x):\r\n",
        "    x = np.array(x,dtype=np.longdouble)\r\n",
        "    e_x = np.exp(x - np.max(x)+200)\r\n",
        "    return e_x / e_x.sum()\r\n",
        "\r\n",
        "def set_nn_shape(verbose=True, num_hidden_layers=-1, hidden_layer_size=-1):\r\n",
        "\r\n",
        "  input_layer_size = 784\r\n",
        "  hidden_layer_size = hidden_layer_size\r\n",
        "  num_hidden_layers = num_hidden_layers\r\n",
        "  output_layer_size = 10\r\n",
        "\r\n",
        "  if (verbose):\r\n",
        "    print(\"\\nNumber Of Hidden Layers:\")\r\n",
        "    num_hidden_layers = int(input())\r\n",
        "\r\n",
        "    print(\"\\nSize Of Each Hidden Layer:\")\r\n",
        "    hidden_layer_size = int(input())\r\n",
        "\r\n",
        "    print(f\"\\nThe Neural Network Has {num_hidden_layers+2} Layers In Total!\")\r\n",
        "  \r\n",
        "  return {\"input_layer_size\": input_layer_size, \"hidden_layer_size\": hidden_layer_size, \"output_layer_size\": output_layer_size, \"num_hidden_layers\": num_hidden_layers}\r\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIFMpZQNItG3"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "def wandb_initializer(nn_shape, weights_list, biases_list, type='random', mu = 0, sigma = 1):\r\n",
        "  \r\n",
        "  # random initialization\r\n",
        "  if (type=='random'):\r\n",
        "    initializer = tf.keras.initializers.TruncatedNormal(mean=mu, stddev=sigma)\r\n",
        "  # xavier initialization\r\n",
        "  elif (type=='xavier'):\r\n",
        "    initializer = tf.keras.initializers.GlorotNormal()\r\n",
        "\r\n",
        "  weights_list.append(initializer(shape=(nn_shape['hidden_layer_size'], nn_shape['input_layer_size'])).numpy())\r\n",
        "  biases_list.append(initializer(shape=(nn_shape['hidden_layer_size'], 1)).numpy())\r\n",
        "  for i in range(nn_shape['num_hidden_layers'] - 1):\r\n",
        "    weights_list.append(initializer(shape=(nn_shape['hidden_layer_size'], nn_shape['hidden_layer_size'])).numpy())\r\n",
        "    biases_list.append(initializer(shape=(nn_shape['hidden_layer_size'], 1)).numpy())\r\n",
        "\r\n",
        "  weights_list.append(initializer(shape=(nn_shape['output_layer_size'], nn_shape['hidden_layer_size'])).numpy())\r\n",
        "  biases_list.append(initializer(shape=(nn_shape['output_layer_size'], 1)).numpy())\r\n",
        "\r\n",
        "  return weights_list, biases_list"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVpF16BtXqB_"
      },
      "source": [
        "class optimizer:\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def sgd_old(network, data, config):\r\n",
        "\r\n",
        "    # num_hidden_layers, hidden_layers_size = config['num_hidden_layers'], config['hidden_layer_size']\r\n",
        "    num_epochs, batch_size = config['num_epochs'], config['batch_size']\r\n",
        "    eta, lambda_ = config['lr'], config['weight_decay']\r\n",
        "    initializer, activation_func = config['weights_initializer'], config['activation']\r\n",
        " \r\n",
        "    ### google the getattr function - eg: getattr(activation, 'relu')(junk) is same as activation.relu(junk)\r\n",
        "    X_train, Y_train = data['train']['X'], data['train']['Y']\r\n",
        "    # print(num_hidden_layers, hidden_layers_size)\r\n",
        "\r\n",
        "    for i in range(num_epochs):\r\n",
        "      dw = []\r\n",
        "      db = []\r\n",
        "      check = 0\r\n",
        "\r\n",
        "      for k in tqdm(range(len(X_train))) :\r\n",
        "        x = X_train[k]\r\n",
        "        y = Y_train[k]\r\n",
        "        temp = network.self_grad_wandb(x,y,activation_func)\r\n",
        "\r\n",
        "        if check==0 :\r\n",
        "          dw = temp['dw']\r\n",
        "          db = temp['db']\r\n",
        "          check=1\r\n",
        "\r\n",
        "        else :\r\n",
        "          for j in range(len(dw)) :\r\n",
        "            dw[j] =dw[j] + temp['dw'][j]\r\n",
        "            db[j] =db[j] + temp['db'][j]\r\n",
        "\r\n",
        "        if (k+1)%batch_size == 0 :\r\n",
        "          for dd in dw :\r\n",
        "            dd *=eta\r\n",
        "          for dd in db :\r\n",
        "            dd *=eta\r\n",
        "          network.update_vals(dw, db)\r\n",
        "          check=0\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def sgd(network, data, config):\r\n",
        "\r\n",
        "    # num_hidden_layers, hidden_layers_size = config['num_hidden_layers'], config['hidden_layer_size']\r\n",
        "    num_epochs, batch_size = config['num_epochs'], config['batch_size']\r\n",
        "    eta, lambda_ = config['lr'], config['weight_decay']\r\n",
        "    initializer, activation_func = config['weights_initializer'], config['activation']\r\n",
        " \r\n",
        "    ### google the getattr function - eg: getattr(activation, 'relu')(junk) is same as activation.relu(junk)\r\n",
        "    X_train, Y_train = data['train']['X'], data['train']['Y']\r\n",
        "    # print(num_hidden_layers, hidden_layers_size)\r\n",
        "\r\n",
        "    for i in range(num_epochs):\r\n",
        "      dw = []\r\n",
        "      db = []\r\n",
        "      for k in tqdm(range(0, len(X_train), batch_size)) :\r\n",
        "        X = X_train[k: k+batch_size]\r\n",
        "        Y = Y_train[k: k+batch_size]\r\n",
        "        temp = network.self_grad_wandb(X, Y, activation_func)\r\n",
        "        for j in range(len(temp['db'])) :\r\n",
        "          temp['db'][j] = np.sum(temp['db'][j],axis=1)\r\n",
        "          \r\n",
        "        dw = temp['dw']\r\n",
        "        db = temp['db']\r\n",
        "        for dd in dw :\r\n",
        "          dd *= eta\r\n",
        "        for dd in db :\r\n",
        "          dd*=eta\r\n",
        "\r\n",
        "        network.update_vals(dw, db)\r\n",
        "      \r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def momentum(X,Y,max_epochs,eta,gamma,batch_size) :\r\n",
        "    test = get_nn_shape()\r\n",
        "    network = neural_network(test,test)\r\n",
        "    dw = []\r\n",
        "    db = []\r\n",
        "    pred1 = []\r\n",
        "    check = 0\r\n",
        "    for i in range(max_epochs) :\r\n",
        "      for k in tqdm(range(len(X))) :\r\n",
        "        x = X[k]\r\n",
        "        y = Y[k]\r\n",
        "        temp = network.self_grad_wandb(x,y)\r\n",
        "        if check==0 :\r\n",
        "          dw = temp['dw']\r\n",
        "          db = temp['db']\r\n",
        "          for dd in db :\r\n",
        "            dd*= eta\r\n",
        "          for dd in dw :\r\n",
        "            dd*=eta\r\n",
        "          check = 1\r\n",
        "        else :\r\n",
        "          for j in range(len(dw)) :\r\n",
        "            dw[j] += eta*temp['dw'][j]\r\n",
        "            db[j] += eta*temp['db'][j]\r\n",
        "        if (k+1) % batch_size == 0 or k == len(X)-1:\r\n",
        "          network.update_vals(dw,db)\r\n",
        "          for dd in db :\r\n",
        "            dd *=gamma\r\n",
        "          for dd in dw :\r\n",
        "            dd*=gamma\r\n",
        "\r\n",
        "      pred = 0\r\n",
        "      for x,y in zip(X,Y) :\r\n",
        "        pred = pred + (network.predict(x)!=y)\r\n",
        "\r\n",
        "      print('error',pred)\r\n",
        "    \r\n",
        "    return pred1\r\n",
        "  \r\n",
        "  @staticmethod\r\n",
        "  def NAG(X,Y,max_epochs,eta,gamma,batch_size) :\r\n",
        "    test = get_nn_shape()\r\n",
        "    network = neural_network(test,test)\r\n",
        "    dw = []\r\n",
        "    db = []\r\n",
        "    check = 0\r\n",
        "    for i in range(max_epochs) :\r\n",
        "      for k in tqdm(range(len(X))) :\r\n",
        "        x = X[k]\r\n",
        "        y = Y[k]\r\n",
        "        temp = network.self_grad_wandb(x,y)\r\n",
        "        if check==0 :\r\n",
        "          dw = temp['dw']\r\n",
        "          db = temp['db']\r\n",
        "          for dd in db :\r\n",
        "            dd*= eta\r\n",
        "          for dd in dw :\r\n",
        "            dd*=eta\r\n",
        "          check = 1\r\n",
        "        else :\r\n",
        "          for j in range(len(dw)) :\r\n",
        "            dw[j] += eta*temp['dw'][j]\r\n",
        "            db[j] += eta*temp['db'][j]\r\n",
        "\r\n",
        "        if (k+1) % batch_size == 0 or k == len(X)-1:\r\n",
        "          network.update_vals(dw,db)\r\n",
        "          for dd in db :\r\n",
        "            dd*=gamma\r\n",
        "          for dd in dw :\r\n",
        "            dd*=gamma\r\n",
        "          network.update_vals(dw,db)\r\n",
        "\r\n",
        "      pred = 0\r\n",
        "      for x,y in zip(X,Y) :\r\n",
        "        pred += (network.predict(x)!=y)\r\n",
        "\r\n",
        "      print('error',pred)\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def RMSprop(X,Y,max_epochs,eta,beta,batch_size,epsilon) :\r\n",
        "    test = get_nn_shape()\r\n",
        "    network = neural_network(test,test)\r\n",
        "    v_dw = []\r\n",
        "    v_db = []\r\n",
        "    check1 = 0\r\n",
        "    for i in range(max_epochs) :\r\n",
        "      dw = []\r\n",
        "      db = []\r\n",
        "      check = 0\r\n",
        "      for k in tqdm(range(len(X))) :\r\n",
        "        x = X[k]\r\n",
        "        y = Y[k]\r\n",
        "        temp = network.self_grad_wandb(x,y)\r\n",
        "        if check==0 :\r\n",
        "          dw = temp['dw']\r\n",
        "          db = temp['db']\r\n",
        "          check = 1\r\n",
        "        else :\r\n",
        "          for j in range(len(dw)) :\r\n",
        "            dw[j] += temp['dw'][j]\r\n",
        "            db[j] += temp['db'][j]\r\n",
        "\r\n",
        "        if (k+1) % batch_size == 0 or k == len(X)-1:\r\n",
        "          if check1==0 :\r\n",
        "            for j in range(len(dw)) :\r\n",
        "              v_dw.append( (1-beta)*(dw[j]**2) )\r\n",
        "              dw[j] *= eta/np.sqrt(v_dw[j]+epsilon)\r\n",
        "\r\n",
        "            for j in range(len(db)) :\r\n",
        "              v_db.append( (1-beta)*(db[j]**2) )\r\n",
        "              db[j] *= eta/np.sqrt(v_db[j]+epsilon)\r\n",
        "\r\n",
        "            check1 = 1\r\n",
        "\r\n",
        "          else :\r\n",
        "            for j in range(len(dw)) :\r\n",
        "              v_dw[j] *= beta\r\n",
        "              v_dw[j] += (1-beta)*(dw[j]**2) \r\n",
        "              dw[j] *= eta/np.sqrt(v_dw[j]+epsilon)\r\n",
        "\r\n",
        "            for j in range(len(db)) :\r\n",
        "              v_db[j] *= beta\r\n",
        "              v_db[j] += (1-beta)*(db[j]**2) \r\n",
        "              db[j] *= eta/np.sqrt(v_db[j]+epsilon)\r\n",
        "\r\n",
        "          network.update_vals(dw,db)\r\n",
        "          check = 1\r\n",
        "\r\n",
        "      pred = 0\r\n",
        "      for x,y in zip(X,Y) :\r\n",
        "        pred += (network.predict(x)!=y)\r\n",
        "\r\n",
        "      print('error',pred)\r\n",
        "\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def adam(X,Y,max_epochs,eta,beta1,beta2,batch_size) :\r\n",
        "    test = get_nn_shape()\r\n",
        "    network = neural_network(test,test)\r\n",
        "    v_dw = []\r\n",
        "    v_db = []\r\n",
        "    m_dw = []\r\n",
        "    m_db = []\r\n",
        "    check1 = 0\r\n",
        "    num_updates = 0\r\n",
        "    for i in range(max_epochs) :\r\n",
        "      dw = []\r\n",
        "      db = []\r\n",
        "      check = 0\r\n",
        "      for k in tqdm(range(len(X))) :\r\n",
        "        x = X[k]\r\n",
        "        y = Y[k]\r\n",
        "        temp = network.self_grad_wandb(x,y)\r\n",
        "        if check==0 :\r\n",
        "          dw = temp['dw']\r\n",
        "          db = temp['db']\r\n",
        "          check = 1\r\n",
        "        else :\r\n",
        "          for j in range(len(dw)) :\r\n",
        "            dw[j] += temp['dw'][j]\r\n",
        "            db[j] += temp['db'][j]\r\n",
        "\r\n",
        "        if (k+1) % batch_size == 0 or k == len(X)-1:\r\n",
        "          if check1==0 :\r\n",
        "            for j in range(len(dw)) :\r\n",
        "              v_dw.append( (1-beta1)*(dw[j]**2) )\r\n",
        "              dw[j] *= eta/np.sqrt(v_dw[j]+epsilon)\r\n",
        "\r\n",
        "            for j in range(len(db)) :\r\n",
        "              v_db.append( (1-beta1)*(db[j]**2) )\r\n",
        "              db[j] *= eta/np.sqrt(v_db[j]+epsilon)\r\n",
        "\r\n",
        "            check1 = 1\r\n",
        "\r\n",
        "          else :\r\n",
        "            for j in range(len(dw)) :\r\n",
        "              v_dw[j] *= beta1\r\n",
        "              v_dw[j] += (1-beta1)*(dw[j]**2) \r\n",
        "              dw[j] *= eta/np.sqrt(v_dw[j]+epsilon)\r\n",
        "\r\n",
        "            for j in range(len(db)) :\r\n",
        "              v_db[j] *= beta1\r\n",
        "              v_db[j] += (1-beta1)*(db[j]**2) \r\n",
        "              db[j] *= eta/np.sqrt(v_db[j]+epsilon)\r\n",
        "\r\n",
        "          network.update_vals(dw,db)\r\n",
        "          check = 1\r\n",
        "\r\n",
        "      pred = 0\r\n",
        "      for x,y in zip(X,Y) :\r\n",
        "        pred += (network.predict(x)!=y)\r\n",
        "\r\n",
        "      print('error',pred)\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKQ-oZvbLOWV"
      },
      "source": [
        "# X = np.array([[1,1,2],[-1,2,3],[10,-67,43],[-5,45,-67]])\n",
        "# Y = np.array([1,0,1,0])\n",
        "# temp = solver.sgd(X,Y,100,1e-3)\n",
        "X=data['train']['X']\n",
        "# print(len(X))\n",
        "# print(X[0])\n",
        "Y = data['train']['y']\n",
        "temp = solver.RMSprop(X,Y,100,0.001,0.9,32,1e-2)\n",
        "print(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535,
          "referenced_widgets": [
            "ef6d7a60b55e480483bdeacbb34f394e",
            "73e6141c6ebe42b49483e6737b17a79f",
            "bc73a7879d7a4542bbfa8813becb427b",
            "86479d64148148548a7001d69c2d3e5b",
            "0a363262c1194105a339a3d0d90efcf1",
            "6b4d5d37e88b4293ad5af537c74c37a8",
            "c1374703a9e54c558370ce4dbade4b62",
            "6e07dcd3773a4674a930978ecca429f3"
          ]
        },
        "id": "Ypd2xySp_dYj",
        "outputId": "673f7000-d6cd-44d9-8d45-e9fb3a507ce0"
      },
      "source": [
        "nn = set_nn_shape()\n",
        "network = neural_network(nn, 'random')\n",
        "#data1 = {'train' : {'X': np.array([[1,1,1],[1,1,1],[1,1,1],[1,1,1],[1,1,1]]), 'Y' : np.array([0,1,3,2,1]) },'val' : {'X': np.array([[1,1,1],[1,1,1],[1,1,1],[1,1,1],[1,1,1]]), 'Y' : np.array([0,1,3,2,1]) }}\n",
        "# need to change this bit later to accomodate other optimization functions\n",
        "config1 = {'num_epochs' : 5,'lr' : 1e-4,'optimizer': 'sgd', 'batch_size' : 3 , 'weights_initializer' : 'random' , 'weight_decay' : 0.001, 'activation' : 'sigmoid' }\n",
        "optimizer.sgd(network, data,config1 )\n",
        "\n",
        "# generating reports for the run\n",
        "report = run_callback(network, data, config1) \n",
        "\n",
        "print(report)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Number Of Hidden Layers:\n",
            "3\n",
            "\n",
            "Size Of Each Hidden Layer:\n",
            "32\n",
            "\n",
            "The Neural Network Has 5 Layers In Total!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef6d7a60b55e480483bdeacbb34f394e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=16667.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-11b5f611bc40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# need to change this bit later to accomodate other optimization functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconfig1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'num_epochs'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lr'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch_size'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'weights_initializer'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'random'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'weight_decay'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'activation'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'sigmoid'\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# generating reports for the run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-84-9c23f39e2ad8>\u001b[0m in \u001b[0;36msgd\u001b[0;34m(network, data, config)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: predict() missing 1 required positional argument: 'activation_func'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cwl2gBj5oVLi",
        "outputId": "c6de1216-5484-4714-e09e-25aac8f0e52f"
      },
      "source": [
        "report = run_callback(network, data, config1) \n",
        "\n",
        "print(report)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'loss': {'train': array([0.        , 0.        , 6.97576531]), 'val': array([0., 0., 0.])}, 'accuracy': {'train': 6.975765306122449, 'val': 0.0}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryQUpU2Wm5o3",
        "outputId": "ce6e3c40-6866-45ab-ffbe-b72326df92ab"
      },
      "source": [
        "a = np.array([1, 0, 3])\n",
        "b = np.zeros((a.size, a.max()+1))\n",
        "b[np.arange(a.size),a] = 1\n",
        "b.T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 0.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKDlM0FUKutJ"
      },
      "source": [
        "def run_callback(network,data,config) :\n",
        "    \n",
        "    activation_func = config['activation']\n",
        "    \n",
        "    X_train = data['train']['X']\n",
        "    Y_train = data['train']['Y']\n",
        "\n",
        "    X_val = data['val']['X']\n",
        "    Y_val = data['val']['Y']\n",
        "\n",
        "    X_test = data['test']['X']\n",
        "    Y_test = data['test']['Y']\n",
        "\n",
        "    train_loss = 0\n",
        "    train_count = 0\n",
        "    train_sq_error = 0\n",
        "    X_train = X_train.T.reshape((784,-1))\n",
        "    temp = network.predict(X_train,activation_func)\n",
        "    train_count = np.sum(np.argmax(temp['y_hat'],axis=0).reshape(Y_train.shape)==Y_train)\n",
        "    #train_loss -= np.log(temp['y_hat'][y]) \n",
        "    #temp['y_hat'][y] = 1 - temp['y_hat'][y]\n",
        "    #train_sq_error += np.sum(np.dot(temp['y_hat'],temp['y_hat']))\n",
        "\n",
        "    val_loss = 0\n",
        "    val_count = 0\n",
        "    val_sq_error = 0\n",
        "    # for x,y in zip(X_val,Y_val) :\n",
        "    #     temp = network.predict(x,activation_func)\n",
        "    #     if temp['y'] == y :\n",
        "    #         val_count += 1\n",
        "    #     val_loss -= np.log(temp['y_hat'][y]) \n",
        "    #     temp['y_hat'][y] = 1 - temp['y_hat'][y]\n",
        "    #     val_sq_error += np.sum(np.dot(temp['y_hat'],temp['y_hat'])) \n",
        "    '''\n",
        "    test_loss = 0\n",
        "    test_count = 0\n",
        "    test_sq_error = 0\n",
        "    for x,y in zip(X_test,Y_test) :\n",
        "        temp = network.predict(x,activation_func)\n",
        "        if temp['y'] == y :\n",
        "            test_count += 1\n",
        "        test_loss -= np.log(temp['y_hat'][y]) \n",
        "        temp['y_hat'][y] = 1 - temp['y_hat'][y]\n",
        "        test_sq_error += np.sum(np.dot(temp['y_hat'],temp['y_hat'])) \n",
        "    '''\n",
        "    return  {\n",
        "        'loss': {\n",
        "            'train' : np.array([train_sq_error,train_loss,train_count])/len(X_train),\n",
        "            'val' : np.array([val_sq_error,val_loss,val_count])/len(X_val)\n",
        "        },\n",
        "        'accuracy': {\n",
        "            'train': train_count / len(X_train),\n",
        "            'val': val_count / len(X_val)\n",
        "        }\n",
        "        #'test' : np.array([test_sq_error,test_loss,test_count])/len(X_test)\n",
        "    }\n",
        "\n",
        "    \n"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaURuG6OPwgs",
        "outputId": "0f997c1b-210f-439a-cd39-eef383cb1857"
      },
      "source": [
        "np.argmax"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "3\n",
            "6\n",
            "9\n",
            "12\n",
            "15\n",
            "18\n",
            "21\n",
            "24\n",
            "27\n",
            "30\n",
            "33\n",
            "36\n",
            "39\n",
            "42\n",
            "45\n",
            "48\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}